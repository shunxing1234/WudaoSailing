[2022-01-18 10:28:52,472] [WARNING] [runner.py:132:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2022-01-18 10:28:52,633] [INFO] [runner.py:398:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=56510 finetune_glm.py --deepspeed --deepspeed_config config_tasks/config_blocklm_10B.json --finetune --cloze-eval --experiment-name blocklm-large-chinese-copa_01-18-10-28 --task COPA --data-dir /data/wang/datasets/finetune_data/COPA --save /data/wang/models/model_save/checkpoints --seq-length 256 --checkpoint-activations --eval-batch-size 16 --save-epoch 100000 --num-workers 1 --no-load-optim --no-load-lr-scheduler --block-lm --cloze-eval --task-mask --num-layers 24 --hidden-size 1024 --num-attention-heads 16 --max-position-embeddings 1024 --tokenizer-type ChineseSPTokenizer --fix-command-token --load-pretrained /data/wang/models/model_save/checkpoints --lr-decay-style linear --warmup 0.1 --weight-decay 1.0e-1 --pattern-id 0 --save-interval 10000 --log-interval 20 --eval-interval 1000 --eval-iters 100 --pattern-id 0 --fp16 --model-parallel-size 1 --epochs 100 --overwrite
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NCCL_DEBUG=info
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NCCL_NET_GDR_LEVEL=2
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NCCL_IB_DISABLE=0
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.11.4-1+cuda10.2
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NCCL_INCLUDE_DIR=/usr/include
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NCCL_VERSION=2.11.4-1
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_VERSION=2.11.4-1
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.11.4-1
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.11.4-1+cuda10.2
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2
[2022-01-18 10:28:53,351] [INFO] [launch.py:73:main] 0 NCCL_LIBRARY=/usr/lib/x86_64-linux-gnu
[2022-01-18 10:28:53,352] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2022-01-18 10:28:53,352] [INFO] [launch.py:86:main] nnodes=1, num_local_procs=4, node_rank=0
[2022-01-18 10:28:53,352] [INFO] [launch.py:99:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2022-01-18 10:28:53,352] [INFO] [launch.py:100:main] dist_world_size=4
[2022-01-18 10:28:53,352] [INFO] [launch.py:102:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
Traceback (most recent call last):
  File "finetune_glm.py", line 453, in <module>
    args = get_args()
  File "/data/wang/models/wudao/examples/glm/arguments.py", line 455, in get_args
    with open(args.deepspeed_config) as file:
FileNotFoundError: [Errno 2] No such file or directory: 'config_tasks/config_blocklm_10B.json'
Traceback (most recent call last):
  File "finetune_glm.py", line 453, in <module>
    args = get_args()
  File "/data/wang/models/wudao/examples/glm/arguments.py", line 455, in get_args
    with open(args.deepspeed_config) as file:
FileNotFoundError: [Errno 2] No such file or directory: 'config_tasks/config_blocklm_10B.json'
Traceback (most recent call last):
  File "finetune_glm.py", line 453, in <module>
    args = get_args()
  File "/data/wang/models/wudao/examples/glm/arguments.py", line 455, in get_args
    with open(args.deepspeed_config) as file:
FileNotFoundError: [Errno 2] No such file or directory: 'config_tasks/config_blocklm_10B.json'
using world size: 4 and model-parallel size: 1 
 > using dynamic loss scaling
Traceback (most recent call last):
  File "finetune_glm.py", line 453, in <module>
    args = get_args()
  File "/data/wang/models/wudao/examples/glm/arguments.py", line 455, in get_args
    with open(args.deepspeed_config) as file:
FileNotFoundError: [Errno 2] No such file or directory: 'config_tasks/config_blocklm_10B.json'
[2022-01-18 10:28:56,393] [INFO] [launch.py:131:sigkill_handler] Killing subprocess 40583
[2022-01-18 10:28:56,393] [INFO] [launch.py:131:sigkill_handler] Killing subprocess 40584
[2022-01-18 10:28:56,393] [INFO] [launch.py:131:sigkill_handler] Killing subprocess 40585
[2022-01-18 10:28:56,393] [INFO] [launch.py:131:sigkill_handler] Killing subprocess 40586
[2022-01-18 10:28:56,393] [ERROR] [launch.py:137:sigkill_handler] ['/opt/conda/bin/python', '-u', 'finetune_glm.py', '--local_rank=3', '--deepspeed', '--deepspeed_config', 'config_tasks/config_blocklm_10B.json', '--finetune', '--cloze-eval', '--experiment-name', 'blocklm-large-chinese-copa_01-18-10-28', '--task', 'COPA', '--data-dir', '/data/wang/datasets/finetune_data/COPA', '--save', '/data/wang/models/model_save/checkpoints', '--seq-length', '256', '--checkpoint-activations', '--eval-batch-size', '16', '--save-epoch', '100000', '--num-workers', '1', '--no-load-optim', '--no-load-lr-scheduler', '--block-lm', '--cloze-eval', '--task-mask', '--num-layers', '24', '--hidden-size', '1024', '--num-attention-heads', '16', '--max-position-embeddings', '1024', '--tokenizer-type', 'ChineseSPTokenizer', '--fix-command-token', '--load-pretrained', '/data/wang/models/model_save/checkpoints', '--lr-decay-style', 'linear', '--warmup', '0.1', '--weight-decay', '1.0e-1', '--pattern-id', '0', '--save-interval', '10000', '--log-interval', '20', '--eval-interval', '1000', '--eval-iters', '100', '--pattern-id', '0', '--fp16', '--model-parallel-size', '1', '--epochs', '100', '--overwrite'] exits with return code = 1
