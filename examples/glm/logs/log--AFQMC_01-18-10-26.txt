[2022-01-18 10:26:16,761] [WARNING] [runner.py:132:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2022-01-18 10:26:16,866] [INFO] [runner.py:398:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=59279 finetune_glm.py --deepspeed --deepspeed_config config_tasks/config_blocklm_10B.json --finetune --cloze-eval --experiment-name -AFQMC_01-18-10-26 --task afqmc --data-dir /data/wang/datasets/finetune_data/lcqmc --save /data/wang/models/model_save/checkpoints --seq-length 256 --checkpoint-activations --eval-batch-size 16 --save-epoch 100000 --num-workers 1 --no-load-optim --no-load-lr-scheduler --lr-decay-style linear --warmup 0.1 --weight-decay 1.0e-1 --pattern-id 0 --save-interval 100 --log-interval 100 --eval-interval 100 --eval-iters 100 --pattern-id 0 --fp16 --model-parallel-size 1 --epochs 10 --overwrite
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NCCL_DEBUG=info
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NCCL_NET_GDR_LEVEL=2
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NCCL_IB_DISABLE=0
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.11.4-1+cuda10.2
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NCCL_INCLUDE_DIR=/usr/include
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NCCL_VERSION=2.11.4-1
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_VERSION=2.11.4-1
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.11.4-1
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.11.4-1+cuda10.2
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2
[2022-01-18 10:26:17,622] [INFO] [launch.py:73:main] 0 NCCL_LIBRARY=/usr/lib/x86_64-linux-gnu
[2022-01-18 10:26:17,622] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2022-01-18 10:26:17,622] [INFO] [launch.py:86:main] nnodes=1, num_local_procs=4, node_rank=0
[2022-01-18 10:26:17,623] [INFO] [launch.py:99:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2022-01-18 10:26:17,623] [INFO] [launch.py:100:main] dist_world_size=4
[2022-01-18 10:26:17,623] [INFO] [launch.py:102:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
Traceback (most recent call last):
  File "finetune_glm.py", line 30, in <module>
    from pretrain_glm import report_iteration_metrics
ImportError: cannot import name 'report_iteration_metrics' from 'pretrain_glm' (/data/wang/models/wudao/examples/glm/pretrain_glm.py)
Traceback (most recent call last):
  File "finetune_glm.py", line 30, in <module>
    from pretrain_glm import report_iteration_metrics
ImportError: cannot import name 'report_iteration_metrics' from 'pretrain_glm' (/data/wang/models/wudao/examples/glm/pretrain_glm.py)
Traceback (most recent call last):
  File "finetune_glm.py", line 30, in <module>
    from pretrain_glm import report_iteration_metrics
ImportError: cannot import name 'report_iteration_metrics' from 'pretrain_glm' (/data/wang/models/wudao/examples/glm/pretrain_glm.py)
Traceback (most recent call last):
  File "finetune_glm.py", line 30, in <module>
    from pretrain_glm import report_iteration_metrics
ImportError: cannot import name 'report_iteration_metrics' from 'pretrain_glm' (/data/wang/models/wudao/examples/glm/pretrain_glm.py)
[2022-01-18 10:26:20,650] [INFO] [launch.py:131:sigkill_handler] Killing subprocess 40531
[2022-01-18 10:26:20,651] [INFO] [launch.py:131:sigkill_handler] Killing subprocess 40532
[2022-01-18 10:26:20,651] [INFO] [launch.py:131:sigkill_handler] Killing subprocess 40533
[2022-01-18 10:26:20,651] [INFO] [launch.py:131:sigkill_handler] Killing subprocess 40534
[2022-01-18 10:26:20,651] [ERROR] [launch.py:137:sigkill_handler] ['/opt/conda/bin/python', '-u', 'finetune_glm.py', '--local_rank=3', '--deepspeed', '--deepspeed_config', 'config_tasks/config_blocklm_10B.json', '--finetune', '--cloze-eval', '--experiment-name', '-AFQMC_01-18-10-26', '--task', 'afqmc', '--data-dir', '/data/wang/datasets/finetune_data/lcqmc', '--save', '/data/wang/models/model_save/checkpoints', '--seq-length', '256', '--checkpoint-activations', '--eval-batch-size', '16', '--save-epoch', '100000', '--num-workers', '1', '--no-load-optim', '--no-load-lr-scheduler', '--lr-decay-style', 'linear', '--warmup', '0.1', '--weight-decay', '1.0e-1', '--pattern-id', '0', '--save-interval', '100', '--log-interval', '100', '--eval-interval', '100', '--eval-iters', '100', '--pattern-id', '0', '--fp16', '--model-parallel-size', '1', '--epochs', '10', '--overwrite'] exits with return code = 1
