[2022-01-04 09:34:43,510] [INFO] [runner.py:327:main] Using IP address of 172.31.32.40 for node V100-3
[2022-01-04 09:34:43,511] [INFO] [runner.py:398:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJWMTAwLTMiOiBbMCwgMSwgMl19 --master_addr=172.31.32.40 --master_port=12770 pretrain_glm.py --block-lm --task-mask --bert-prob 0.4 --gap-sentence-prob 0.3 --avg-block-length 3 --gpt-min-ratio 0.25 --block-mask-prob 0.1 --short-seq-prob 0.02 --experiment-name blocklm-large-chinese --model-parallel-size 1 --num-layers 24 --hidden-size 1024 --num-attention-heads 16 --seq-length 512 --max-position-embeddings 1024 --save ../model_save/checkpoints/ --load ../model_save/checkpoints/ --log-interval 50 --eval-interval 1000 --save-interval 2000 --train-iters 250000000 --train-data wudao --resume-dataloader --loader-scatter 4 --no-lazy-loader --tokenizer-type ChineseSPTokenizer --fix-command-token --split 949,50,1 --distributed-backend nccl --lr-decay-style cosine --lr-decay-ratio 0.1 --lr-decay-iters 200000 --warmup 0.04 --checkpoint-activations --deepspeed-activation-checkpointing --fp16 --deepspeed --deepspeed_config ./config/config_block_large_chinese.json
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NCCL_DEBUG=info
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NCCL_NET_GDR_LEVEL=2
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NCCL_IB_DISABLE=0
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.11.4-1+cuda10.2
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NCCL_INCLUDE_DIR=/usr/include
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NCCL_VERSION=2.11.4-1
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_VERSION=2.11.4-1
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.11.4-1
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.11.4-1+cuda10.2
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2
[2022-01-04 09:34:44,227] [INFO] [launch.py:73:main] 0 NCCL_LIBRARY=/usr/lib/x86_64-linux-gnu
[2022-01-04 09:34:44,227] [INFO] [launch.py:80:main] WORLD INFO DICT: {'V100-3': [0, 1, 2]}
[2022-01-04 09:34:44,227] [INFO] [launch.py:86:main] nnodes=1, num_local_procs=3, node_rank=0
[2022-01-04 09:34:44,227] [INFO] [launch.py:99:main] global_rank_mapping=defaultdict(<class 'list'>, {'V100-3': [0, 1, 2]})
[2022-01-04 09:34:44,227] [INFO] [launch.py:100:main] dist_world_size=3
[2022-01-04 09:34:44,227] [INFO] [launch.py:102:main] Setting CUDA_VISIBLE_DEVICES=0,1,2
using world size: 3 and model-parallel size: 1 
 > using dynamic loss scaling
> initializing model parallel with size 1
[2022-01-04 09:34:52,434] [INFO] [checkpointing.py:795:_configure_using_config_file] {'partition_activations': False, 'contiguous_memory_optimization': False, 'cpu_checkpointing': False, 'number_checkpoints': None, 'synchronize_checkpoint_boundary': False, 'profile': False}
[2022-01-04 09:34:52,434] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
{'pad': 50000, 'eos': 50000, 'sep': 50001, 'ENC': 50002, 'MASK': 50003, 'unk': 50004, 'sop': 50006, 'eop': 50007, 'sMASK': 50008, 'gMASK': 50009, 'dBLOCK': 50010}
> padded vocab (size: 50011) with 37 dummy tokens (new size: 50048)
> found end-of-document token: 50000
