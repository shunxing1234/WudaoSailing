[2022-01-12 08:57:19,358] [INFO] [runner.py:327:main] Using IP address of 172.31.32.40 for node V100-3
[2022-01-12 08:57:19,359] [INFO] [runner.py:398:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJWMTAwLTMiOiBbMCwgMSwgMl19 --master_addr=172.31.32.40 --master_port=50521 pretrain_glm.py --block-lm --task-mask --bert-prob 0.4 --gap-sentence-prob 0.3 --avg-block-length 3 --gpt-min-ratio 0.25 --block-mask-prob 0.1 --short-seq-prob 0.02 --experiment-name blocklm-large-chinese --model-parallel-size 1 --num-layers 24 --hidden-size 1024 --num-attention-heads 16 --seq-length 512 --max-position-embeddings 1024 --save ../model_save/checkpoints/ --load ../model_save/checkpoints/ --log-interval 50 --eval-interval 1000 --save-interval 2000 --train-iters 250000000 --train-data wudao --resume-dataloader --loader-scatter 4 --no-lazy-loader --tokenizer-type ChineseSPTokenizer --fix-command-token --split 949,50,1 --distributed-backend nccl --lr-decay-style cosine --lr-decay-ratio 0.1 --lr-decay-iters 200000 --warmup 0.04 --checkpoint-activations --deepspeed-activation-checkpointing --fp16 --deepspeed --deepspeed_config ./config/config_block_large_chinese.json
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NCCL_DEBUG=info
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NCCL_NET_GDR_LEVEL=2
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NCCL_IB_DISABLE=0
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.11.4-1+cuda10.2
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NCCL_INCLUDE_DIR=/usr/include
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NCCL_VERSION=2.11.4-1
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_VERSION=2.11.4-1
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.11.4-1
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.11.4-1+cuda10.2
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2
[2022-01-12 08:57:19,995] [INFO] [launch.py:73:main] 0 NCCL_LIBRARY=/usr/lib/x86_64-linux-gnu
[2022-01-12 08:57:19,995] [INFO] [launch.py:80:main] WORLD INFO DICT: {'V100-3': [0, 1, 2]}
[2022-01-12 08:57:19,995] [INFO] [launch.py:86:main] nnodes=1, num_local_procs=3, node_rank=0
[2022-01-12 08:57:19,995] [INFO] [launch.py:99:main] global_rank_mapping=defaultdict(<class 'list'>, {'V100-3': [0, 1, 2]})
[2022-01-12 08:57:19,995] [INFO] [launch.py:100:main] dist_world_size=3
[2022-01-12 08:57:19,995] [INFO] [launch.py:102:main] Setting CUDA_VISIBLE_DEVICES=0,1,2
using world size: 3 and model-parallel size: 1 
 > using dynamic loss scaling
> initializing model parallel with size 1
[2022-01-12 08:57:26,540] [INFO] [checkpointing.py:795:_configure_using_config_file] {'partition_activations': False, 'contiguous_memory_optimization': False, 'cpu_checkpointing': False, 'number_checkpoints': None, 'synchronize_checkpoint_boundary': False, 'profile': False}
[2022-01-12 08:57:26,541] [INFO] [checkpointing.py:226:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
{'pad': 50000, 'eos': 50000, 'sep': 50001, 'ENC': 50002, 'MASK': 50003, 'unk': 50004, 'sop': 50006, 'eop': 50007, 'sMASK': 50008, 'gMASK': 50009, 'dBLOCK': 50010}
> padded vocab (size: 50011) with 37 dummy tokens (new size: 50048)
> found end-of-document token: 50000
glm_dist16:26190:26190 [2] NCCL INFO Bootstrap : Using bond1:172.31.32.40<0>
glm_dist16:26190:26190 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
glm_dist16:26190:26190 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
glm_dist16:26190:26190 [2] NCCL INFO NET/IB : No device found.
glm_dist16:26190:26190 [2] NCCL INFO NET/Socket : Using [0]bond1:172.31.32.40<0> [1]vethf76a3c0:fe80::1c70:26ff:fe30:6d88%vethf76a3c0<0> [2]vethe25bc53:fe80::7c24:adff:fe52:b43d%vethe25bc53<0>
glm_dist16:26190:26190 [2] NCCL INFO Using network Socket
NCCL version 2.11.4+cuda10.2
glm_dist16:26190:26214 [2] NCCL INFO Channel 00/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 01/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 02/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 03/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 04/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 05/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 06/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 07/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 08/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 09/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 10/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 11/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 12/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 13/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 14/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 15/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 16/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 17/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 18/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 19/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 20/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 21/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 22/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 23/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 24/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 25/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 26/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 27/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 28/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 29/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 30/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Channel 31/32 :    0
glm_dist16:26190:26214 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
glm_dist16:26190:26214 [2] NCCL INFO Setting affinity for GPU 2 to 3ffff0,0003ffff
glm_dist16:26190:26214 [2] NCCL INFO Connected all rings
glm_dist16:26190:26214 [2] NCCL INFO Connected all trees
glm_dist16:26190:26214 [2] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
glm_dist16:26190:26214 [2] NCCL INFO comm 0x7fab18006a20 rank 0 nranks 1 cudaDev 2 busId 1d000 - Init COMPLETE
Rank 2 is using scatter from /data/wang/glm/jinrongdata.scatter/2
glm_dist16:26189:26189 [1] NCCL INFO Bootstrap : Using bond1:172.31.32.40<0>
glm_dist16:26189:26189 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
glm_dist16:26189:26189 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
glm_dist16:26189:26189 [1] NCCL INFO NET/IB : No device found.
glm_dist16:26189:26189 [1] NCCL INFO NET/Socket : Using [0]bond1:172.31.32.40<0> [1]vethf76a3c0:fe80::1c70:26ff:fe30:6d88%vethf76a3c0<0> [2]vethe25bc53:fe80::7c24:adff:fe52:b43d%vethe25bc53<0>
glm_dist16:26189:26189 [1] NCCL INFO Using network Socket
NCCL version 2.11.4+cuda10.2
glm_dist16:26189:26218 [1] NCCL INFO Channel 00/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 01/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 02/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 03/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 04/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 05/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 06/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 07/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 08/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 09/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 10/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 11/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 12/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 13/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 14/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 15/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 16/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 17/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 18/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 19/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 20/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 21/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 22/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 23/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 24/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 25/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 26/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 27/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 28/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 29/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 30/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Channel 31/32 :    0
glm_dist16:26189:26218 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
glm_dist16:26189:26218 [1] NCCL INFO Setting affinity for GPU 1 to 3ffff0,0003ffff
glm_dist16:26188:26188 [0] NCCL INFO Bootstrap : Using bond1:172.31.32.40<0>
glm_dist16:26188:26188 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
glm_dist16:26188:26188 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
glm_dist16:26188:26188 [0] NCCL INFO NET/IB : No device found.
glm_dist16:26188:26188 [0] NCCL INFO NET/Socket : Using [0]bond1:172.31.32.40<0> [1]vethf76a3c0:fe80::1c70:26ff:fe30:6d88%vethf76a3c0<0> [2]vethe25bc53:fe80::7c24:adff:fe52:b43d%vethe25bc53<0>
glm_dist16:26188:26188 [0] NCCL INFO Using network Socket
NCCL version 2.11.4+cuda10.2
glm_dist16:26189:26218 [1] NCCL INFO Connected all rings
glm_dist16:26189:26218 [1] NCCL INFO Connected all trees
glm_dist16:26189:26218 [1] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
glm_dist16:26189:26218 [1] NCCL INFO comm 0x7f4c08006a20 rank 0 nranks 1 cudaDev 1 busId 1c000 - Init COMPLETE
Rank 1 is using scatter from /data/wang/glm/jinrongdata.scatter/1
glm_dist16:26188:26221 [0] NCCL INFO Channel 00/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 01/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 02/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 03/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 04/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 05/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 06/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 07/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 08/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 09/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 10/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 11/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 12/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 13/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 14/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 15/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 16/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 17/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 18/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 19/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 20/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 21/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 22/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 23/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 24/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 25/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 26/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 27/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 28/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 29/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 30/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Channel 31/32 :    0
glm_dist16:26188:26221 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
glm_dist16:26188:26221 [0] NCCL INFO Setting affinity for GPU 0 to 3ffff0,0003ffff
glm_dist16:26188:26221 [0] NCCL INFO Connected all rings
glm_dist16:26188:26221 [0] NCCL INFO Connected all trees
glm_dist16:26188:26221 [0] NCCL INFO 32 coll channels, 32 p2p channels, 32 p2p channels per peer
glm_dist16:26188:26221 [0] NCCL INFO comm 0x7fb354006a20 rank 0 nranks 1 cudaDev 0 busId 1b000 - Init COMPLETE
configuring data
Rank 0 is using scatter from /data/wang/glm/jinrongdata.scatter/0
Create dataset wudao at scatter 0 with 30099 documents
[43358, 6499, 43861, 43398, 43524, 3621, 30422, 43389, 6499, 43861, 43398, 43524, 3621, 43399, 43361, 6499, 43861, 32871, 16887, 77, 3528, 43367, 1084, 43367, 3621, 3287, 43367, 912, 23015, 43498, 43367, 4132, 43367, 858, 43367, 7972, 6805, 23955, 43359, 422, 2792, 7791, 3621, 43405, 3045, 43361, 6551, 43359, 6499, 43861, 4348, 43370, 888, 4795, 170, 43397, 43392, 22000, 43423, 43861, 632, 4348, 65, 1423, 7791, 10345, 80, 43361, 6499, 7523, 17261, 6469, 43359, 542, 7, 6728, 3621, 43384, 10345, 80, 2194, 43359, 1423, 791, 1655, 1082, 43367, 3954, 43367, 7637, 43367, 11108, 43384, 2927, 43477, 6499, 3118, 43361, 6499, 43861, 43398, 43524, 3621, 43399, 43361, 6499, 43861, 32871, 16887, 77, 3528, 43367, 1084, 43367, 3621, 3287, 43367, 912, 23015, 43498, 43367, 4132, 43367, 858, 43367, 7972, 6805, 23955, 43359, 422, 2792, 7791, 3621, 43405, 3045, 43361, 6551, 43359, 6499, 43861, 4348, 43370, 888, 4795, 170, 43397, 43392, 22000, 43423, 43861, 632, 4348, 65, 1423, 7791, 10345, 80, 43361, 6499, 7523, 17261, 6469, 43359, 542, 7, 6728, 3621, 43384, 10345, 80, 2194, 43359, 1423, 791, 1655, 1082, 43367, 3954, 43367, 7637, 43367, 11108, 43384, 2927, 43477, 6499, 3118, 43361]
社保卡能当身份证用吗?社保卡能当身份证用。社保卡记录了参保人的姓名、照片、身份证号码、出生年月日、性别、民族、户籍所在地等信息,因此是可以当做身份证来使用的。此外,社保卡激活了金融账户之后(可直接在发卡银行激活),还可以当做银行卡使用。社保卡的用处多多,除了可以当作身份证和银行卡使用之外,还可以用于办理医疗、养老、失业、工伤和生育等社保事务。社保卡能当身份证用。社保卡记录了参保人的姓名、照片、身份证号码、出生年月日、性别、民族、户籍所在地等信息,因此是可以当做身份证来使用的。此外,社保卡激活了金融账户之后(可直接在发卡银行激活),还可以当做银行卡使用。社保卡的用处多多,除了可以当作身份证和银行卡使用之外,还可以用于办理医疗、养老、失业、工伤和生育等社保事务。
[132, 180, 307, 277, 15981, 10499, 904, 11297, 1585, 43389, 407, 904, 11297, 1585, 92, 290, 1234, 44326, 277, 80, 43359, 43444, 2316, 43367, 1658, 43367, 1485, 43367, 3663, 43367, 4592, 43477, 43359, 253, 3663, 43367, 4592, 37883, 4182, 2506, 43361, 6551, 4592, 43367, 2170, 43367, 43714, 43753, 43367, 6330, 43367, 10220, 44411, 43367, 4427, 43367, 43571, 44371, 43367, 13346, 43367, 1658, 43367, 5933, 43367, 4542, 43367, 15894, 43367, 7306, 43367, 1801, 43367, 16595, 11502, 1423, 22000, 904, 43378, 3723, 10743, 6499, 43861, 43359, 392, 10743, 478, 6499, 43861, 43410, 43359, 440, 43373, 108, 5056, 620, 1455, 4944, 241, 43588, 43637, 9389, 43360, 17149, 43361, 25755, 10743, 478, 6499, 43861, 30437, 8773, 3323, 290, 904, 11297, 1585, 43361, 6330, 43367, 7306, 43367, 1801, 43367, 4542, 43367, 1658, 43367, 5933, 43367, 2316, 11502, 43373, 43425, 43491, 100, 43498, 43538, 43425, 43491, 131, 43498, 10743, 6499, 43861, 78, 80, 904, 11297, 15981, 43359, 1423, 301, 904, 11297, 1585, 5729, 492, 43623, 3126, 43359, 243, 407, 10757, 231, 92, 13920, 43361, 904, 11297, 1585, 10757, 241, 9111, 17306, 43359, 55, 11035, 1759, 43361]
018哪些城市看病可以使用微信医保支付?目前微信医保支付已经支持55座城市使用,如成都、深圳、广东、广西、甘肃等,其中广西、甘肃已实现全省覆盖。此外甘肃、合肥、白城、长沙、葫芦岛、青岛、常熟、邯郸、深圳、郑州、厦门、开封、宁波、武汉、延安的用户还可以直接在微信中授权绑定社保卡,成功绑定电子社保卡后,就可以在个人页面查看当地可用功能及已接入的医疗机构。如果不能绑定电子社保卡就说明所在城市还不支持微信医保支付。长沙、宁波、武汉、厦门、深圳、郑州、成都的用户在6月11日—6月30日绑定社保卡或者使用微信医保看病,还可以获得微信医保支付提供的健康金奖励,不过目前这项活动已经过期。微信医保支付这项功能还是比较方便的,需要的话可以试试。
[43358, 13278, 12921, 43428, 44178, 44094, 55, 723, 307, 1160, 43389, 13278, 12921, 43428, 44178, 44094, 55, 640, 723, 11640, 43359, 12921, 703, 43383, 7876, 44697, 43954, 43373, 4796, 44554, 43520, 2674, 43598, 44009, 43359, 4050, 12921, 13570, 43359, 440, 45188, 43361, 12641, 2575, 43383, 311, 286, 12539, 583, 1402, 3230, 82, 43945, 43371, 43359, 15221, 2575, 43659, 7886, 44038, 43459, 43405, 18635, 43361, 1402, 14868, 12429, 43383, 19, 4796, 44554, 43520, 4049, 4732, 43567, 43414, 44119, 43477, 43359, 42719, 1555, 22659, 9428, 44697, 2337, 659, 43359, 15221, 2575, 43659, 7886, 43405, 1528, 43361, 13278, 12921, 43428, 44178, 44094, 55, 640, 723, 11640, 43359, 12921, 703, 43383, 7876, 44697, 43954, 43373, 4796, 44554, 43520, 2674, 43598, 44009, 43359, 4050, 12921, 13570, 43359, 440, 45188, 43361, 12641, 2575, 43383, 311, 286, 12539, 583, 1402, 3230, 82, 43945, 43371, 43359, 15221, 2575, 43659, 7886, 44038, 43459, 43405, 18635, 43361, 1402, 14868, 12429, 43383, 19, 4796, 44554, 43520, 4049, 4732, 43567, 43414, 44119, 43477, 43359, 42719, 1555, 22659, 9428, 44697, 2337, 659, 43359, 15221, 2575, 43659, 7886, 43405, 1528, 43361]
投保房东家财险需要关注哪些保障?投保房东家财险需要重点关注三点,房东责任:万一租客在出租屋内意外身故,如果有房东的责任,就可以赔。租金损失:比如发生火灾导致房屋暂时不能住人,这部分损失由保险公司按天来赔付。房屋声誉受损:如果出租屋内发生了自杀或他杀等,那么这个房子短期内很可能租不出去了,这部分损失由保险公司来承担。投保房东家财险需要重点关注三点,房东责任:万一租客在出租屋内意外身故,如果有房东的责任,就可以赔。租金损失:比如发生火灾导致房屋暂时不能住人,这部分损失由保险公司按天来赔付。房屋声誉受损:如果出租屋内发生了自杀或他杀等,那么这个房子短期内很可能租不出去了,这部分损失由保险公司来承担。
[16818, 82, 18239, 21630, 43389, 692, 10264, 45188, 4605, 294, 227, 35713, 43359, 55, 130, 7097, 43367, 9387, 43367, 4958, 23810, 43383, 7097, 43383, 43806, 7886, 7097, 43359, 74, 25069, 1863, 43359, 12358, 1235, 1744, 6780, 43378, 43359, 7886, 7, 4214, 6255, 43359, 349, 43469, 1680, 1998, 43361, 9387, 43383, 9387, 701, 43576, 43693, 7886, 29430, 17268, 9387, 43603, 43359, 5747, 44406, 692, 31101, 43405, 294, 692, 6255, 43359, 13289, 692, 6255, 525, 8377, 5923, 341, 43361, 4958, 43383, 9507, 43500, 1590, 227, 43359, 141, 43806, 2228, 4958, 1998, 15166, 5026, 43370, 43359, 39499, 43604, 44501, 45077, 44080, 43361, 692, 10264, 45188, 4605, 294, 227, 35713, 43359, 55, 130, 7097, 43367, 9387, 43367, 4958, 23810, 43383, 7097, 43383, 43806, 7886, 7097, 43359, 74, 25069, 1863, 43359, 12358, 1235, 1744, 6780, 43378, 43359, 7886, 7, 4214, 6255, 43359, 349, 43469, 1680, 1998, 43361, 9387, 43383, 9387, 701, 43576, 43693, 7886, 29430, 17268, 9387, 43603, 43359, 5747, 44406, 692, 31101, 43405, 294, 692, 6255, 43359, 13289, 692, 6255, 525, 8377, 5923, 341, 43361, 4958, 43383, 9507, 43500, 1590, 227, 43359, 141, 43806, 2228, 4958, 1998, 15166, 5026, 43370, 43359, 39499, 43604, 44501, 45077, 44080, 43361]
保险不能理赔怎么处理?保险不理赔一般的处理方式有三种,需要通过协商、仲裁、诉讼来解决:协商:找保险公司协商,进行直接的沟通,如果在符合事实的原则中,保险公司可以消除纠纷,这是最理想的方式。仲裁:仲裁委员会从各保险公司聘任了一批仲裁员,有一些懂保险的人士来处理保险纠纷,能使保险纠纷得到公正合理的解决。诉讼:相对于前两种方式,这种找法院诉讼的方式就比较激烈了,通常会两败俱伤。保险不理赔一般的处理方式有三种,需要通过协商、仲裁、诉讼来解决:协商:找保险公司协商,进行直接的沟通,如果在符合事实的原则中,保险公司可以消除纠纷,这是最理想的方式。仲裁:仲裁委员会从各保险公司聘任了一批仲裁员,有一些懂保险的人士来处理保险纠纷,能使保险纠纷得到公正合理的解决。诉讼:相对于前两种方式,这种找法院诉讼的方式就比较激烈了,通常会两败俱伤。
[1433, 4682, 6992, 4450, 1160, 2674, 1095, 692, 39415, 43807, 3027, 43573, 44033, 43396, 103, 537, 43389, 462, 4682, 6992, 4450, 1160, 2674, 1095, 692, 39415, 43807, 3027, 43573, 44033, 43396, 14756, 537, 43383, 26, 1181, 43383, 4682, 10201, 4253, 103, 1181, 43383, 4682, 6992, 4450, 1160, 2674, 1095, 692, 39415, 43807, 3027, 43573, 44033, 43396, 103, 5285, 43383, 2674, 1095, 692, 43400, 2674, 1095, 692, 101, 566, 43383, 638, 43705, 103, 103, 1153, 1879, 43383, 43531, 44136, 43602, 227, 43383, 108, 692, 871, 566, 43383, 5898, 43397, 848, 43588, 848, 746, 43396, 103, 43723, 43833, 227, 43383, 13584, 43723, 43833, 8716, 43723, 43833, 38612, 103, 8325, 1531, 6561, 43383, 4682, 3954, 43641, 1202, 43644, 2674, 1095, 692, 43364, 164, 43729, 103, 630, 645, 43383, 44388, 44232, 2918, 630, 373, 43383, 1448, 6855, 161]
求平安附加残疾保障意外伤害保险(2013版)(C款)产品介绍?关于平安附加残疾保障意外伤害保险(2013版)(C款)基本信息介绍:公司名称:平安养老保险股份有限公司产品名称:平安附加残疾保障意外伤害保险(2013版)(C款)产品类别:意外伤害保险-意外伤害保险设计类型:传统型产品产品特殊属性:无承保方式:个人保险期间类型:短期(一年及一年以下)产品交费方式:分期交费一次性交费兼有产品条款文字编码:平安养老[2013]意外伤害保险025号产品销售状态:停售停止销售日期:2017-04-0
[43358, 6131, 43388, 43833, 44150, 44442, 43368, 4891, 216, 43689, 43389, 19, 6131, 43388, 43833, 24436, 411, 273, 21177, 4399, 43490, 43636, 44265, 696, 4891, 43359, 135, 685, 44150, 44442, 24436, 43388, 43833, 1730, 696, 4891, 3200, 43361, 43471, 6131, 43388, 43833, 24436, 411, 43544, 273, 21177, 4399, 43359, 135, 379, 21177, 4399, 1040, 216, 440, 24436, 43388, 43833, 43359, 43636, 44265, 696, 4891, 22280, 216, 43361, 422, 43359, 6131, 43388, 43833, 44150, 44442, 4230, 4891, 216, 43359, 4654, 43423, 43861, 14342, 43388, 43833, 24436, 451, 43361, 1124, 6131, 379, 21177, 4399, 636, 1988, 14218, 440, 24436, 43388, 43833, 43359, 240, 2866, 6131, 43388, 43833, 24436, 55, 43636, 44265, 696, 4891, 1040, 133, 14218, 43361, 19, 6131, 43388, 43833, 24436, 411, 273, 21177, 4399, 43490, 43636, 44265, 696, 4891, 43359, 135, 685, 44150, 44442, 24436, 43388, 43833, 1730, 696, 4891, 3200, 43361, 43471, 6131, 43388, 43833, 24436, 411, 43544, 273, 21177, 4399, 43359, 135, 379, 21177, 4399, 1040, 216, 440, 24436, 43388, 43833, 43359, 43636, 44265, 696, 4891, 22280, 216, 43361, 422, 43359, 6131, 43388, 43833, 44150, 44442, 4230, 4891, 216, 43359, 4654, 43423, 43861, 14342, 43388, 43833, 24436, 451, 43361, 1124, 6131, 379, 21177, 4399, 636, 1988, 14218, 440, 24436, 43388, 43833, 43359, 240, 2866, 6131, 43388, 43833, 24436, 55, 43636, 44265, 696, 4891, 1040, 133, 14218, 43361]
信用卡年费补刷有金额要求吗?如果信用卡年费减免条件包括刷卡次数与单笔消费金额,那么申请补刷减免年费就有消费金额的要求。而信用卡年费减免条件只包括刷卡次数,那么只要刷卡次数满足要求就可以减免年费,单笔消费金额不作要求。因此,信用卡年费补刷是否有金额要求,要看发卡银行的年费减免规定。大部分信用卡只要刷卡次数达到一定的数额就可以减免年费,只有少数信用卡年费减免需要单笔消费金额满足一定数额。如果信用卡年费减免条件包括刷卡次数与单笔消费金额,那么申请补刷减免年费就有消费金额的要求。而信用卡年费减免条件只包括刷卡次数,那么只要刷卡次数满足要求就可以减免年费,单笔消费金额不作要求。因此,信用卡年费补刷是否有金额要求,要看发卡银行的年费减免规定。大部分信用卡只要刷卡次数达到一定的数额就可以减免年费,只有少数信用卡年费减免需要单笔消费金额满足一定数额。
[27110, 43770, 13078, 43394, 13415, 43689, 43389, 3373, 7519, 13078, 14023, 13415, 43360, 43361, 3373, 43770, 44644, 44320, 44791, 43360, 13078, 20610, 240, 43445, 43459, 43359, 439, 14944, 43445, 16281, 1213, 1786, 685, 43359, 2163, 13078, 43394, 214, 43420, 44899, 43361, 3373, 43770, 43993, 43847, 44791, 17687, 43568, 43368, 131, 43459, 43359, 30714, 216, 34922, 131, 16281, 74, 2682, 9669, 43359, 1406, 20610, 43359, 66, 1736, 29281, 13078, 43420, 44899, 43361, 422, 43359, 3373, 43770, 4206, 13078, 43410, 43359, 14944, 451, 22588, 4550, 1786, 685, 43359, 1406, 20610, 43359, 439, 365, 874, 3108, 1786, 13078, 43361, 3373, 7519, 13078, 14023, 13415, 43360, 43361, 3373, 43770, 44644, 44320, 44791, 43360, 13078, 20610, 240, 43445, 43459, 43359, 439, 14944, 43445, 16281, 1213, 1786, 685, 43359, 2163, 13078, 43394, 214, 43420, 44899, 43361, 3373, 43770, 43993, 43847, 44791, 17687, 43568, 43368, 131, 43459, 43359, 30714, 216, 34922, 131, 16281, 74, 2682, 9669, 43359, 1406, 20610, 43359, 66, 1736, 29281, 13078, 43420, 44899, 43361, 422, 43359, 3373, 43770, 4206, 13078, 43410, 43359, 14944, 451, 22588, 4550, 1786, 685, 43359, 1406, 20610, 43359, 439, 365, 874, 3108, 1786, 13078, 43361]
有钱花额度会失效吗?有钱花的额度是会失效的。有钱花尊享贷的额度有效期只有7天,用户必须在7天内提出贷款申请,否则额度会直接作废。有钱花满易贷的有效期有30天,但是也要求用户在30天内进行首次借款,过了有效期,系统同样会将额度作废。因此,有钱花获得了额度后,必须在规定的时间内提交贷款申请,过了有效期,用户必须重新获取贷款额度。有钱花的额度是会失效的。有钱花尊享贷的额度有效期只有7天,用户必须在7天内提出贷款申请,否则额度会直接作废。有钱花满易贷的有效期有30天,但是也要求用户在30天内进行首次借款,过了有效期,系统同样会将额度作废。因此,有钱花获得了额度后,必须在规定的时间内提交贷款申请,过了有效期,用户必须重新获取贷款额度。
[43358, 24476, 43798, 44498, 15411, 43444, 43710, 43798, 44498, 24476, 43359, 2368, 5814, 43500, 1038, 434, 289, 43403, 6241, 22327, 4347, 78, 64, 24687, 647, 1655, 43798, 44498, 641, 43359, 43798, 44498, 3197, 42282, 8041, 1966, 2278, 9427, 1655, 43430, 6424, 43403, 43942, 43432, 43365, 8041, 15411, 43359, 24476, 43430, 6424, 43403, 43942, 43432, 641, 374, 1655, 251, 36014, 1655, 43430, 6424, 43403, 43942, 43432, 43384, 43430, 29100, 43798, 44498, 43432, 641, 43395, 43359, 19, 20407, 44139, 14903, 4624, 43624, 29100, 43359, 43663, 44150, 43650, 34526, 43359, 19, 20407, 44139, 14903, 3746, 43624, 29100, 43360, 43359, 43663, 28734, 34526, 43359, 243, 34526, 142, 43663, 283, 44325, 44139, 43833, 305, 8041, 15411, 43361, 2263, 12358, 5814, 43500, 1038, 434, 43726, 152, 43459, 5872, 43359, 43663, 24476, 43798, 44498, 43377, 44377, 5814, 37, 152, 43459, 2615, 114, 6329, 29100, 43359, 43609, 10151, 5814, 152, 43459, 43500, 44325, 36049, 43359, 8041, 6643, 15411, 43361, 43444, 43710, 43798, 44498, 24476, 43359, 2368, 5814, 43500, 1038, 434, 289, 43403, 6241, 22327, 4347, 78, 64, 24687, 647, 1655, 43798, 44498, 641, 43359, 43798, 44498, 3197, 42282, 8041, 1966, 2278, 9427, 1655, 43430, 6424, 43403, 43942, 43432, 43365, 8041, 15411, 43359, 24476, 43430, 6424, 43403, 43942, 43432, 641, 374, 1655, 251, 36014, 1655, 43430, 6424, 43403, 43942, 43432, 43384, 43430, 29100, 43798, 44498, 43432, 641, 43395, 43359, 19, 20407, 44139, 14903, 4624, 43624, 29100, 43359, 43663, 44150, 43650, 34526, 43359, 19, 20407, 44139, 14903, 3746, 43624, 29100, 43360, 43359, 43663, 28734, 34526, 43359, 243, 34526, 142, 43663, 283, 44325, 44139, 43833, 305, 8041, 15411, 43361, 2263, 12358, 5814, 43500, 1038, 434, 43726, 152, 43459, 5872, 43359, 43663, 24476, 43798, 44498, 43377, 44377, 5814, 37, 152, 43459, 2615, 114, 6329, 29100, 43359, 43609, 10151, 5814, 152, 43459, 43500, 44325, 36049, 43359, 8041, 6643, 15411, 43361]
火车票改签手续费如需改签火车票,可以在开车前48小时以上到车站售票窗口或者12306网站办理改签业务,改签的手续费收取规则如下:1、办理“变更到站”不收取手续费,火车票“变更到站”业务只能办理一次。2、办理“变更到站”和“车票改签”业务时,如果新车票票价高于原车票,将补收差额,如果新车票票价低于原车票的,将退还差额,不过差额部分将根据退票费标准收取手续费。3、如果在开车前48小时至15天之内,将火车票改签为距开车时间15天以上的其他列车车票,并又在开车15天前退票的,收取5%手续费。如需改签火车票,可以在开车前48小时以上到车站售票窗口或者12306网站办理改签业务,改签的手续费收取规则如下:1、办理“变更到站”不收取手续费,火车票“变更到站”业务只能办理一次。2、办理“变更到站”和“车票改签”业务时,如果新车票票价高于原车票,将补收差额,如果新车票票价低于原车票的,将退还差额,不过差额部分将根据退票费标准收取手续费。3、如果在开车前48小时至15天之内,将火车票改签为距开车时间15天以上的其他列车车票,并又在开车15天前退票的,收取5%手续费。
[43358, 1102, 33699, 4884, 43389, 1102, 33699, 26100, 873, 938, 43498, 1102, 71, 938, 43361, 2831, 1102, 33699, 15656, 43913, 11612, 17122, 43359, 2607, 43576, 43411, 3535, 43726, 100, 3535, 43359, 2939, 43576, 239, 2017, 43726, 152, 2017, 43361, 2732, 21703, 7158, 43361, 1102, 855, 1561, 3286, 43367, 1167, 43882, 44225, 43360, 6842, 3659, 334, 227, 43359, 130, 1716, 1102, 266, 43359, 1782, 334, 1086, 1135, 43359, 43659, 1102, 17953, 43371, 17953, 43359, 1102, 46, 43371, 6492, 2134, 1135, 43359, 1073, 2820, 43367, 8649, 43367, 10474, 43367, 3572, 43477, 888, 1063, 334, 43359, 43379, 301, 334, 2439, 43384, 1678, 5570, 43361, 1102, 33699, 26100, 873, 938, 43498, 1102, 71, 938, 43361, 2831, 1102, 33699, 15656, 43913, 11612, 17122, 43359, 2607, 43576, 43411, 3535, 43726, 100, 3535, 43359, 2939, 43576, 239, 2017, 43726, 152, 2017, 43361, 2732, 21703, 7158, 43361, 1102, 855, 1561, 3286, 43367, 1167, 43882, 44225, 43360, 6842, 3659, 334, 227, 43359, 130, 1716, 1102, 266, 43359, 1782, 334, 1086, 1135, 43359, 43659, 1102, 17953, 43371, 17953, 43359, 1102, 46, 43371, 6492, 2134, 1135, 43359, 1073, 2820, 43367, 8649, 43367, 10474, 43367, 3572, 43477, 888, 1063, 334, 43359, 43379, 301, 334, 2439, 43384, 1678, 5570, 43361]
基金开盘是什么意思?基金开盘的意思是每个交易日基金开始交易。中国的基金开盘时间是周一到周五,早上从9:30至11:30,下午从13:00至15:00。法定节假日除外。基金是一种利益共享、风险共担的集合证券投资方式,通过发行基金单位,集中投资者的资金,由基金托管人托管,基金管理人管理和运用资金,从事股票、债券、外汇、货币等金融工具投资,以获得投资收益和资本增值。基金开盘的意思是每个交易日基金开始交易。中国的基金开盘时间是周一到周五,早上从9:30至11:30,下午从13:00至15:00。法定节假日除外。基金是一种利益共享、风险共担的集合证券投资方式,通过发行基金单位,集中投资者的资金,由基金托管人托管,基金管理人管理和运用资金,从事股票、债券、外汇、货币等金融工具投资,以获得投资收益和资本增值。
[43358, 7886, 38421, 7847, 1172, 44908, 45188, 43689, 43389, 7886, 38421, 7847, 1172, 9228, 492, 5167, 216, 43471, 44908, 45188, 43359, 7886, 216, 5167, 22787, 1920, 3310, 43562, 28384, 15619, 43367, 7847, 43367, 18894, 43367, 6413, 19116, 36098, 43360, 43359, 7847, 4119, 39108, 5167, 10111, 43361, 47, 43359, 2128, 43373, 35635, 3917, 43359, 116, 4602, 43480, 7847, 43367, 333, 12074, 15981, 43359, 5615, 159, 18239, 43359, 8222, 928, 1889, 43359, 3365, 1324, 15393, 43359, 5615, 8718, 1206, 380, 7459, 43361, 7886, 38421, 7847, 1172, 9228, 492, 5167, 216, 43471, 44908, 45188, 43359, 7886, 216, 5167, 22787, 1920, 3310, 43562, 28384, 15619, 43367, 7847, 43367, 18894, 43367, 6413, 19116, 36098, 43360, 43359, 7847, 4119, 39108, 5167, 10111, 43361, 47, 43359, 2128, 43373, 35635, 3917, 43359, 116, 4602, 43480, 7847, 43367, 333, 12074, 15981, 43359, 5615, 159, 18239, 43359, 8222, 928, 1889, 43359, 3365, 1324, 15393, 43359, 5615, 8718, 1206, 380, 7459, 43361]
保险公司能以体检记录拒赔吗?保险公司能以体检记录不符合健康告知要求而拒赔,保险公司要求告知的健康状况是以被保险人就诊、体检、服药、住院等情况为依据的,体检的结果也属于告知范畴。所以,消费者在买保险前后,不要随意去体检、医院门诊看病,以免影响理赔,但是在必要的情况下,还是要及时就医,以免错过最佳治疗时机。保险公司能以体检记录不符合健康告知要求而拒赔,保险公司要求告知的健康状况是以被保险人就诊、体检、服药、住院等情况为依据的,体检的结果也属于告知范畴。所以,消费者在买保险前后,不要随意去体检、医院门诊看病,以免影响理赔,但是在必要的情况下,还是要及时就医,以免错过最佳治疗时机。
glm_dist16:26188:26226 [0] NCCL INFO Channel 00/02 :    0   1   2
glm_dist16:26190:26227 [2] NCCL INFO Trees [0] -1/-1/-1->2->1 [1] -1/-1/-1->2->1
glm_dist16:26189:26228 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
glm_dist16:26188:26226 [0] NCCL INFO Channel 01/02 :    0   1   2
glm_dist16:26190:26227 [2] NCCL INFO Setting affinity for GPU 2 to 3ffff0,0003ffff
glm_dist16:26189:26228 [1] NCCL INFO Setting affinity for GPU 1 to 3ffff0,0003ffff
glm_dist16:26188:26226 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
glm_dist16:26188:26226 [0] NCCL INFO Setting affinity for GPU 0 to 3ffff0,0003ffff
glm_dist16:26190:26227 [2] NCCL INFO Channel 00 : 2[1d000] -> 0[1b000] via P2P/IPC
glm_dist16:26189:26228 [1] NCCL INFO Channel 00 : 1[1c000] -> 2[1d000] via P2P/IPC
glm_dist16:26188:26226 [0] NCCL INFO Channel 00 : 0[1b000] -> 1[1c000] via P2P/IPC
glm_dist16:26190:26227 [2] NCCL INFO Channel 01 : 2[1d000] -> 0[1b000] via P2P/IPC
glm_dist16:26189:26228 [1] NCCL INFO Channel 01 : 1[1c000] -> 2[1d000] via P2P/IPC
glm_dist16:26188:26226 [0] NCCL INFO Channel 01 : 0[1b000] -> 1[1c000] via P2P/IPC
glm_dist16:26190:26227 [2] NCCL INFO Connected all rings
glm_dist16:26189:26228 [1] NCCL INFO Connected all rings
glm_dist16:26188:26226 [0] NCCL INFO Connected all rings
glm_dist16:26190:26227 [2] NCCL INFO Channel 00 : 2[1d000] -> 1[1c000] via P2P/IPC
glm_dist16:26190:26227 [2] NCCL INFO Channel 01 : 2[1d000] -> 1[1c000] via P2P/IPC
glm_dist16:26189:26228 [1] NCCL INFO Channel 00 : 1[1c000] -> 0[1b000] via P2P/IPC
glm_dist16:26189:26228 [1] NCCL INFO Channel 01 : 1[1c000] -> 0[1b000] via P2P/IPC
glm_dist16:26190:26227 [2] NCCL INFO Connected all trees
glm_dist16:26190:26227 [2] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/512
glm_dist16:26190:26227 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
glm_dist16:26188:26226 [0] NCCL INFO Connected all trees
glm_dist16:26188:26226 [0] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/512
glm_dist16:26188:26226 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
glm_dist16:26189:26228 [1] NCCL INFO Connected all trees
glm_dist16:26189:26228 [1] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/512
glm_dist16:26189:26228 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
glm_dist16:26190:26227 [2] NCCL INFO comm 0x7fab180aaaf0 rank 2 nranks 3 cudaDev 2 busId 1d000 - Init COMPLETE
glm_dist16:26189:26228 [1] NCCL INFO comm 0x7f4c080aaaf0 rank 1 nranks 3 cudaDev 1 busId 1c000 - Init COMPLETE
glm_dist16:26188:26226 [0] NCCL INFO comm 0x7fb358006a20 rank 0 nranks 3 cudaDev 0 busId 1b000 - Init COMPLETE
glm_dist16:26188:26188 [0] NCCL INFO Launch mode Parallel
Create dataset wudao at scatter 1 with 30099 documents
[5294, 8239, 305, 45198, 938, 1966, 245, 43389, 239, 8239, 305, 45198, 43362, 30517, 43478, 9391, 43519, 30929, 43661, 45350, 43630, 26557, 6429, 4454, 8649, 43359, 7026, 43508, 43710, 283, 8649, 3635, 43564, 454, 938, 43359, 10712, 43498, 22000, 938, 309, 43476, 1405, 14516, 43359, 1507, 2527, 15134, 43361, 407, 18693, 8239, 305, 45198, 11599, 3182, 239, 8239, 26832, 25151, 43393, 43362, 43393, 43459, 43568, 45081, 26557, 43359, 392, 26557, 43410, 8649, 2527, 16407, 43359, 5953, 10947, 43359, 500, 26557, 1966, 43379, 103, 537, 11717, 43359, 43444, 43594, 43858, 24841, 43384, 227, 43361, 239, 8239, 305, 45198, 43362, 30517, 43478, 9391, 43519, 30929, 43661, 45350, 43630, 26557, 6429, 4454, 8649, 43359, 7026, 43508, 43710, 283, 8649, 3635, 43564, 454, 938, 43359, 10712, 43498, 22000, 938, 309, 43476, 1405, 14516, 43359, 1507, 2527, 15134, 43361, 407, 18693, 8239, 305, 45198, 11599, 3182, 239, 8239, 26832, 25151, 43393, 43362, 43393, 43459, 43568, 45081, 26557, 43359, 392, 26557, 43410, 8649, 2527, 16407, 43359, 5953, 10947, 43359, 500, 26557, 1966, 43379, 103, 537, 11717, 43359, 43444, 43594, 43858, 24841, 43384, 227, 43361]
131990标准券交易规则是什么?131990标准券是上交所推出的新国债质押式回购的标准抵押债券,持有者需根据债券的天数操作交易,到期日直接在交易软件里点击卖出,输入代码便可。目前,131990标准券已知的有131990RC-003是3天期债回购,成功回购后债券代码会变,投资者不用担心,具体回购规则以产品介绍为准,如计息天数和方式。131990标准券是上交所推出的新国债质押式回购的标准抵押债券,持有者需根据债券的天数操作交易,到期日直接在交易软件里点击卖出,输入代码便可。目前,131990标准券已知的有131990RC-003是3天期债回购,成功回购后债券代码会变,投资者不用担心,具体回购规则以产品介绍为准,如计息天数和方式。
[43358, 28259, 55, 2925, 43826, 17914, 3960, 43360, 1786, 4884, 43389, 28259, 55, 2925, 43826, 17914, 3960, 43360, 1786, 1700, 439, 4298, 10, 7, 26572, 43826, 17914, 43360, 1786, 43359, 3610, 1786, 92, 1655, 43370, 43826, 17914, 2925, 43359, 8707, 1694, 74, 2925, 43361, 422, 43359, 43524, 8758, 1786, 10, 1655, 43826, 17914, 2925, 43359, 23516, 211, 571, 2173, 43359, 439, 7, 757, 632, 24306, 3598, 74, 816, 43361, 9527, 43359, 379, 1786, 7, 26572, 43826, 17914, 43359, 135, 5056, 17512, 43392, 2925, 43360, 2173, 43359, 240, 82, 2925, 43360, 43359, 2546, 10, 2925, 43360, 3736, 43361, 28259, 55, 2925, 43826, 17914, 3960, 43360, 1786, 1700, 439, 4298, 10, 7, 26572, 43826, 17914, 43360, 1786, 43359, 3610, 1786, 92, 1655, 43370, 43826, 17914, 2925, 43359, 8707, 1694, 74, 2925, 43361, 422, 43359, 43524, 8758, 1786, 10, 1655, 43826, 17914, 2925, 43359, 23516, 211, 571, 2173, 43359, 439, 7, 757, 632, 24306, 3598, 74, 816, 43361, 9527, 43359, 379, 1786, 7, 26572, 43826, 17914, 43359, 135, 5056, 17512, 43392, 2925, 43360, 2173, 43359, 240, 82, 2925, 43360, 43359, 2546, 10, 2925, 43360, 3736, 43361]
暂无需要转换LPR利率的贷款是什么意思?暂无需要转换LPR利率的贷款是指用户当前没有可以转换为LPR的贷款,或者是贷款已经办理了LPR转换,不支持再次进行转换。因此,当用户的贷款没有办理LPR转换,但是又出现这样的提示,用户可以联系银行的人工客服进行咨询。一般来说,只要贷款可以转换为LPR,那么页面就会出现可转换的提示,只有不能转换的,才会没有转换的选项。暂无需要转换LPR利率的贷款是指用户当前没有可以转换为LPR的贷款,或者是贷款已经办理了LPR转换,不支持再次进行转换。因此,当用户的贷款没有办理LPR转换,但是又出现这样的提示,用户可以联系银行的人工客服进行咨询。一般来说,只要贷款可以转换为LPR,那么页面就会出现可转换的提示,只有不能转换的,才会没有转换的选项。
[725, 43587, 632, 3017, 24, 10743, 6131, 43389, 36059, 632, 3017, 10743, 6131, 10855, 3329, 2278, 9427, 42418, 330, 178, 668, 43463, 43861, 536, 4675, 43359, 43609, 420, 4792, 43549, 1024, 18351, 43373, 43430, 69, 43432, 5056, 1405, 43430, 11080, 46, 137, 2263, 1507, 1487, 34784, 6131, 43861, 43729, 43367, 43762, 43861, 43371, 3528, 43359, 43609, 420, 3470, 4360, 34888, 662, 6131, 1585, 2205, 43359, 1182, 43361, 36059, 632, 3017, 44169, 290, 10743, 1487, 34784, 6131, 43359, 82, 10743, 2759, 6131, 43359, 47, 229, 4301, 43710, 1953, 31665, 43359, 2163, 418, 10743, 392, 43361, 36059, 632, 3017, 10743, 6131, 10855, 3329, 2278, 9427, 42418, 330, 178, 668, 43463, 43861, 536, 4675, 43359, 43609, 420, 4792, 43549, 1024, 18351, 43373, 43430, 69, 43432, 5056, 1405, 43430, 11080, 46, 137, 2263, 1507, 1487, 34784, 6131, 43861, 43729, 43367, 43762, 43861, 43371, 3528, 43359, 43609, 420, 3470, 4360, 34888, 662, 6131, 1585, 2205, 43359, 1182, 43361, 36059, 632, 3017, 44169, 290, 10743, 1487, 34784, 6131, 43359, 82, 10743, 2759, 6131, 43359, 47, 229, 4301, 43710, 1953, 31665, 43359, 2163, 418, 10743, 392, 43361]
中信银行app怎么绑定信用卡?中信银行app绑定信用卡的操作步骤如下:1、在手机应用市场下载动卡空间APP,并完成登录/注册;2、在“我的”页面点击“卡片管理”,3、输入本人名下信用卡卡号、持卡人姓名,并完成短信验证;4、设置信用卡支付密码,即可。中信银行app仅支持绑定本人名下信用卡,不能绑定他人信用卡,所以提供的信息需准确无误,否则无法绑定成功。中信银行app绑定信用卡的操作步骤如下:1、在手机应用市场下载动卡空间APP,并完成登录/注册;2、在“我的”页面点击“卡片管理”,3、输入本人名下信用卡卡号、持卡人姓名,并完成短信验证;4、设置信用卡支付密码,即可。中信银行app仅支持绑定本人名下信用卡,不能绑定他人信用卡,所以提供的信息需准确无误,否则无法绑定成功。
[1439, 45292, 1215, 44803, 44320, 43807, 13693, 692, 703, 245, 43389, 8386, 43568, 3294, 43389, 13275, 1215, 44803, 44320, 43807, 26960, 18783, 13693, 703, 43383, 5420, 41782, 1061, 4335, 18635, 43384, 26013, 4335, 18635, 43359, 236, 703, 48, 45188, 2485, 43834, 23726, 43361, 5420, 41782, 1061, 43999, 4355, 4801, 43383, 7082, 36398, 44647, 43367, 21523, 7410, 44704, 44555, 43608, 43384, 44025, 32121, 25691, 43361, 243, 23998, 8386, 43568, 150, 43383, 2682, 38844, 5420, 41782, 6731, 43359, 1116, 18635, 11201, 23726, 43475, 31209, 4335, 9682, 5420, 41782, 1061, 43359, 18635, 2485, 43834, 43360, 23726, 43359, 8386, 43568, 43362, 43366, 43388, 43361, 2682, 38844, 5420, 41782, 6731, 43359, 1116, 18635, 11201, 23726, 43475, 31209, 4335, 9682, 5420, 41782, 1061, 43359, 18635, 2485, 43834, 43360, 23726, 43359, 8386, 43568, 43362, 43366, 43388, 43361, 2682, 9682, 26013, 43359, 45188, 81, 11201, 23726, 43359, 19, 43393, 4709, 26013, 1236, 43367, 43519, 43423, 43367, 14686, 43567, 2867, 43477, 43359, 18635, 2485, 43834, 43360, 23726, 43359, 8386, 43568, 43362, 43393, 43388, 43361, 13275, 1215, 44803, 44320, 43807, 26960, 18783, 13693, 703, 43383, 5420, 41782, 1061, 4335, 18635, 43384, 26013, 4335, 18635, 43359, 236, 703, 48, 45188, 2485, 43834, 23726, 43361, 5420, 41782, 1061, 43999, 4355, 4801, 43383, 7082, 36398, 44647, 43367, 21523, 7410, 44704, 44555, 43608, 43384, 44025, 32121, 25691, 43361, 243, 23998, 8386, 43568, 150, 43383, 2682, 38844, 5420, 41782, 6731, 43359, 1116, 18635, 11201, 23726, 43475, 31209, 4335, 9682, 5420, 41782, 1061, 43359, 18635, 2485, 43834, 43360, 23726, 43359, 8386, 43568, 43362, 43366, 43388, 43361, 2682, 38844, 5420, 41782, 6731, 43359, 1116, 18635, 11201, 23726, 43475, 31209, 4335, 9682, 5420, 41782, 1061, 43359, 18635, 2485, 43834, 43360, 23726, 43359, 8386, 43568, 43362, 43366, 43388, 43361, 2682, 9682, 26013, 43359, 45188, 81, 11201, 23726, 43359, 19, 43393, 4709, 26013, 1236, 43367, 43519, 43423, 43367, 14686, 43567, 2867, 43477, 43359, 18635, 2485, 43834, 43360, 23726, 43359, 8386, 43568, 43362, 43393, 43388, 43361]
无忧人生惠享版可选保险责任是什么?间隔期多久?无忧人生惠享版一共有两项可选责任:特定心脑血管疾病二次赔付和恶性肿瘤二次赔付,两个责任都是赔120%保额。特定心脑血管疾病约定了三种:急性心肌梗塞、冠状动脉搭桥术和脑中风后遗症。不过约定的间隔期不同:首次患上特定心脑血管疾病的,第一次赔付重疾保额;一年后二次确诊特定心脑血管疾病,赔付120%的保额,间隔期是1年。首次患上特定心脑血管疾病的,第一次赔付重疾保额;一年后二次确诊特定心脑血管疾病,赔付120%的保额,间隔期是1年。首次确诊恶性肿瘤,赔的是重疾保额,如果3年后恶性肿瘤持续、新发、复发或转移等,赔付120%的保额,间隔期是3年。无忧人生惠享版一共有两项可选责任:特定心脑血管疾病二次赔付和恶性肿瘤二次赔付,两个责任都是赔120%保额。特定心脑血管疾病约定了三种:急性心肌梗塞、冠状动脉搭桥术和脑中风后遗症。不过约定的间隔期不同:首次患上特定心脑血管疾病的,第一次赔付重疾保额;一年后二次确诊特定心脑血管疾病,赔付120%的保额,间隔期是1年。首次患上特定心脑血管疾病的,第一次赔付重疾保额;一年后二次确诊特定心脑血管疾病,赔付120%的保额,间隔期是1年。首次确诊恶性肿瘤,赔的是重疾保额,如果3年后恶性肿瘤持续、新发、复发或转移等,赔付120%的保额,间隔期是3年。
[547, 44365, 1786, 43441, 1541, 43394, 43905, 44526, 1740, 43689, 43389, 29718, 1786, 43365, 1923, 43905, 44526, 1740, 43359, 43511, 159, 36381, 43361, 29718, 1786, 557, 108, 1786, 43359, 30925, 14383, 43365, 1923, 159, 43479, 1487, 22898, 43359, 19153, 43422, 19814, 888, 641, 1655, 183, 696, 43477, 671, 159, 43361, 43511, 1655, 16045, 43367, 43648, 44791, 43477, 3495, 1017, 1786, 43359, 183, 495, 185, 1017, 30925, 685, 20617, 1786, 43395, 43359, 9669, 77, 14383, 1172, 406, 43422, 1786, 4282, 42381, 43361, 44381, 43521, 45511, 44033, 1028, 44002, 43441, 43359, 43562, 632, 43567, 1786, 389, 7869, 43370, 43359, 386, 3571, 43988, 43587, 43562, 895, 43371, 43359, 135, 4092, 10775, 422, 418, 5818, 43454, 3013, 12378, 107, 43361, 29718, 1786, 43365, 1923, 43905, 44526, 1740, 43359, 43511, 159, 36381, 43361, 29718, 1786, 557, 108, 1786, 43359, 30925, 14383, 43365, 1923, 159, 43479, 1487, 22898, 43359, 19153, 43422, 19814, 888, 641, 1655, 183, 696, 43477, 671, 159, 43361, 43511, 1655, 16045, 43367, 43648, 44791, 43477, 3495, 1017, 1786, 43359, 183, 495, 185, 1017, 30925, 685, 20617, 1786, 43395, 43359, 9669, 77, 14383, 1172, 406, 43422, 1786, 4282, 42381, 43361, 44381, 43521, 45511, 44033, 1028, 44002, 43441, 43359, 43562, 632, 43567, 1786, 389, 7869, 43370, 43359, 386, 3571, 43988, 43587, 43562, 895, 43371, 43359, 135, 4092, 10775, 422, 418, 5818, 43454, 3013, 12378, 107, 43361]
小额贷款还不上会连累家人吗?小额贷款不还会连累家人,但影响不是很大。小额贷款属于个人贷款,借款人逾期不还会影响其本人征信,一般不会对家人的金融业务办理以及消费等造成影响。但办理房贷、车贷等夫妻共同贷款,以及父母作为共同借款人申请助学贷款时,借款人的逾期记录就会对贷款审批产生影响。若因欠款长期未还,被银行或贷款机构起诉了,甚至成为了失信被执行人,那么子女也将因此无法就读高收费私立学校。小额贷款不还会连累家人,但影响不是很大。小额贷款属于个人贷款,借款人逾期不还会影响其本人征信,一般不会对家人的金融业务办理以及消费等造成影响。但办理房贷、车贷等夫妻共同贷款,以及父母作为共同借款人申请助学贷款时,借款人的逾期记录就会对贷款审批产生影响。若因欠款长期未还,被银行或贷款机构起诉了,甚至成为了失信被执行人,那么子女也将因此无法就读高收费私立学校。
[11553, 43443, 44628, 43988, 170, 440, 43746, 43519, 43861, 43689, 43389, 41030, 44628, 43988, 170, 31656, 43519, 43861, 808, 55, 43445, 43459, 37, 43359, 43762, 43861, 2122, 166, 10345, 7971, 43410, 12170, 457, 44628, 43988, 43359, 229, 43762, 43861, 43371, 3621, 43367, 10345, 43729, 43367, 18802, 43443, 43367, 183, 8496, 4301, 4212, 44628, 43988, 43359, 4212, 44628, 43988, 170, 43861, 3456, 3230, 16895, 43359, 1871, 871, 440, 5376, 3621, 43480, 41030, 2797, 13990, 1655, 31656, 43519, 7523, 641, 43361, 43576, 71, 31656, 43403, 43421, 43861, 55, 2635, 3315, 43359, 43762, 43861, 20831, 11025, 130, 840, 632, 43359, 43663, 4795, 43520, 1135, 2867, 15812, 610, 2115, 43861, 43520, 43405, 20809, 45105, 44442, 1167, 43361, 41030, 44628, 43988, 170, 31656, 43519, 43861, 808, 55, 43445, 43459, 37, 43359, 43762, 43861, 2122, 166, 10345, 7971, 43410, 12170, 457, 44628, 43988, 43359, 229, 43762, 43861, 43371, 3621, 43367, 10345, 43729, 43367, 18802, 43443, 43367, 183, 8496, 4301, 4212, 44628, 43988, 43359, 4212, 44628, 43988, 170, 43861, 3456, 3230, 16895, 43359, 1871, 871, 440, 5376, 3621, 43480, 41030, 2797, 13990, 1655, 31656, 43519, 7523, 641, 43361, 43576, 71, 31656, 43403, 43421, 43861, 55, 2635, 3315, 43359, 43762, 43861, 20831, 11025, 130, 840, 632, 43359, 43663, 4795, 43520, 1135, 2867, 15812, 610, 2115, 43861, 43520, 43405, 20809, 45105, 44442, 1167, 43361]
建行挂失之后就可以办新卡吗?建行挂失之后补办新卡大概需要7天时间,持卡人在发现银行卡丢失后可以先电话挂失,提供持卡人身份证、银行卡号、开户行、以及余额的信息临时挂失,临时挂失之后卡会被暂时冻结,在这期间就可以携带身份证去建行营业网点办理补办新卡的业务。从开始补办到下卡需要等待一段时间,持卡人可以第一时间通过网上银行,将账户内资金转移到自己另外一张卡内来规避盗刷风险。建行挂失之后补办新卡大概需要7天时间,持卡人在发现银行卡丢失后可以先电话挂失,提供持卡人身份证、银行卡号、开户行、以及余额的信息临时挂失,临时挂失之后卡会被暂时冻结,在这期间就可以携带身份证去建行营业网点办理补办新卡的业务。从开始补办到下卡需要等待一段时间,持卡人可以第一时间通过网上银行,将账户内资金转移到自己另外一张卡内来规避盗刷风险。
[576, 28489, 619, 692, 24, 43781, 43389, 3984, 44988, 619, 692, 8595, 1414, 5537, 17009, 43359, 55, 80, 177, 904, 45100, 43363, 45100, 11939, 10467, 425, 692, 3184, 5056, 43359, 7797, 13278, 145, 43367, 1332, 9836, 26380, 145, 43477, 43359, 420, 2081, 12107, 43929, 1089, 392, 43361, 243, 43359, 407, 3984, 44988, 619, 692, 92, 30179, 43359, 418, 31944, 43359, 28, 141, 692, 9228, 43602, 22939, 238, 692, 103, 4200, 346, 27005, 451, 43361, 3984, 44988, 619, 692, 8595, 1414, 5537, 17009, 43359, 55, 80, 177, 904, 45100, 43363, 45100, 11939, 10467, 425, 692, 3184, 5056, 43359, 7797, 13278, 145, 43367, 1332, 9836, 26380, 145, 43477, 43359, 420, 2081, 12107, 43929, 1089, 392, 43361, 243, 43359, 407, 3984, 44988, 619, 692, 92, 30179, 43359, 418, 31944, 43359, 28, 141, 692, 9228, 43602, 22939, 238, 692, 103, 4200, 346, 27005, 451, 43361]
中国人寿爱情保险怎么买?中国人寿爱情保险是通过互联网的形式购买的,需要使用手机微信扫一扫专属二维码进入保险详情页面,填写投保信息、恋爱凭证邮寄信息等,完成在线缴费即购买成功。不过,目前中国人寿爱情保险已经下架,无法购买了,因为这种保险不符合保监会对于保险产品设计的相关法令规定。中国人寿爱情保险是通过互联网的形式购买的,需要使用手机微信扫一扫专属二维码进入保险详情页面,填写投保信息、恋爱凭证邮寄信息等,完成在线缴费即购买成功。不过,目前中国人寿爱情保险已经下架,无法购买了,因为这种保险不符合保监会对于保险产品设计的相关法令规定。
[8880, 1786, 44090, 2091, 457, 2481, 43719, 39482, 43689, 43389, 19, 7656, 1786, 43362, 11630, 9782, 43360, 43359, 135, 1786, 26, 6709, 43613, 32122, 457, 43360, 43359, 422, 32122, 99, 882, 410, 159, 43361, 43471, 7656, 1786, 14383, 43359, 1786, 26, 418, 757, 43387, 1786, 43371, 1487, 43359, 5649, 406, 18545, 757, 77, 457, 74, 45445, 43650, 43359, 135, 757, 77, 13437, 34295, 133, 1886, 43361, 28424, 1453, 6438, 1786, 43359, 32122, 1960, 6438, 43371, 43359, 422, 1156, 7656, 1786, 14383, 43359, 32122, 36676, 1528, 410, 24545, 43361, 19, 7656, 1786, 43362, 11630, 9782, 43360, 43359, 135, 1786, 26, 6709, 43613, 32122, 457, 43360, 43359, 422, 32122, 99, 882, 410, 159, 43361, 43471, 7656, 1786, 14383, 43359, 1786, 26, 418, 757, 43387, 1786, 43371, 1487, 43359, 5649, 406, 18545, 757, 77, 457, 74, 45445, 43650, 43359, 135, 757, 77, 13437, 34295, 133, 1886, 43361, 28424, 1453, 6438, 1786, 43359, 32122, 1960, 6438, 43371, 43359, 422, 1156, 7656, 1786, 14383, 43359, 32122, 36676, 1528, 410, 24545, 43361]
朋友贷款留了我电话我会受牵连吗?如果朋友的贷款是按时还款的,那么贷款公司是不会打联系人电话的,因此联系人不会受到任何影响。而朋友的贷款逾期,贷款公司无法联系上贷款人本人,这时候就会拨打联系人的电话进行催收,那么联系人的日常生活会受到一定的影响。但这个并不是担保贷款,联系人也不是担保人,因此即使朋友的贷款逾期,联系人是不需要承担任何责任的。如果朋友的贷款是按时还款的,那么贷款公司是不会打联系人电话的,因此联系人不会受到任何影响。而朋友的贷款逾期,贷款公司无法联系上贷款人本人,这时候就会拨打联系人的电话进行催收,那么联系人的日常生活会受到一定的影响。但这个并不是担保贷款,联系人也不是担保人,因此即使朋友的贷款逾期,联系人是不需要承担任何责任的。
[43358, 2090, 43602, 15380, 692, 1784, 43389, 2090, 43602, 92, 16618, 2090, 43677, 43359, 349, 43659, 11409, 1243, 43397, 272, 43396, 260, 15907, 347, 185, 6986, 11583, 222, 17273, 1243, 229, 1854, 16264, 458, 405, 43359, 273, 28193, 16264, 458, 43367, 2752, 44010, 45149, 16264, 458, 43367, 4578, 43799, 16264, 458, 43367, 34129, 2674, 16264, 458, 43359, 7256, 43373, 5491, 905, 43361, 930, 16264, 14684, 1417, 43359, 11660, 685, 16264, 43623, 43359, 43710, 4550, 19215, 43397, 273, 3621, 43620, 43367, 1061, 2688, 43627, 43477, 65, 774, 496, 1375, 2868, 43410, 74, 3144, 13138, 43359, 130, 43410, 43359, 16264, 458, 193, 1417, 1017, 31283, 16264, 43623, 43361, 2090, 43602, 92, 16618, 2090, 43677, 43359, 349, 43659, 11409, 1243, 43397, 272, 43396, 260, 15907, 347, 185, 6986, 11583, 222, 17273, 1243, 229, 1854, 16264, 458, 405, 43359, 273, 28193, 16264, 458, 43367, 2752, 44010, 45149, 16264, 458, 43367, 4578, 43799, 16264, 458, 43367, 34129, 2674, 16264, 458, 43359, 7256, 43373, 5491, 905, 43361, 930, 16264, 14684, 1417, 43359, 11660, 685, 16264, 43623, 43359, 43710, 4550, 19215, 43397, 273, 3621, 43620, 43367, 1061, 2688, 43627, 43477, 65, 774, 496, 1375, 2868, 43410, 74, 3144, 13138, 43359, 130, 43410, 43359, 16264, 458, 193, 1417, 1017, 31283, 16264, 43623, 43361]
相互保是哪个保险公司的?相互保已经改名为相互宝,这是由蚂蚁会员(北京)网络技术服务有限公司作为发起者和组织者为会员提供的一种互助计划系列,包括大病互助计划、老年防癌互助计划、慢性病互助计划、公共交通意外互助计划,可以直接在支付宝加入。参与互助计划的成员,如果要申请互助金,需提交相关资料(包括身份证件、疾病诊断书等),经过平台调查审核后进行案件公示,通过后,互助计划所有成员共同分摊互助金。相互保已经改名为相互宝,这是由蚂蚁会员(北京)网络技术服务有限公司作为发起者和组织者为会员提供的一种互助计划系列,包括大病互助计划、老年防癌互助计划、慢性病互助计划、公共交通意外互助计划,可以直接在支付宝加入。参与互助计划的成员,如果要申请互助金,需提交相关资料(包括身份证件、疾病诊断书等),经过平台调查审核后进行案件公示,通过后,互助计划所有成员共同分摊互助金。
[38109, 24, 43781, 43658, 43942, 2820, 43389, 5491, 82, 43781, 43658, 43942, 2820, 43361, 5491, 10, 1924, 2820, 5470, 6704, 43361, 43658, 43942, 43929, 38607, 43359, 5112, 43841, 2898, 12626, 44176, 35553, 2580, 43361, 47, 5953, 19, 10593, 43658, 43942, 115, 43359, 7923, 5079, 43557, 44279, 4795, 43361, 41395, 7, 5079, 43557, 44279, 4795, 3182, 8120, 3659, 43367, 44149, 44617, 3659, 43477, 43361, 468, 5953, 639, 930, 43557, 44279, 938, 5293, 6530, 15858, 43359, 13707, 1639, 43361, 47, 407, 4950, 15279, 43360, 43359, 5953, 32, 43412, 930, 9, 11399, 334, 2319, 43361, 5491, 82, 43781, 43658, 43942, 2820, 43361, 5491, 10, 1924, 2820, 5470, 6704, 43361, 43658, 43942, 43929, 38607, 43359, 5112, 43841, 2898, 12626, 44176, 35553, 2580, 43361, 47, 5953, 19, 10593, 43658, 43942, 115, 43359, 7923, 5079, 43557, 44279, 4795, 43361, 41395, 7, 5079, 43557, 44279, 4795, 3182, 8120, 3659, 43367, 44149, 44617, 3659, 43477, 43361, 468, 5953, 639, 930, 43557, 44279, 938, 5293, 6530, 15858, 43359, 13707, 1639, 43361, 47, 407, 4950, 15279, 43360, 43359, 5953, 32, 43412, 930, 9, 11399, 334, 2319, 43361]
支付宝怎么买b站股票?支付宝不能买b站股票。支付宝没有代理股票买卖权限。b站即哔哩哔哩,在美国NASDAQ证券交易所上市。所以投资者如果想买b站的话,就得开通美股账户。目前国内可以开通美股账户的有老虎证券、富途证券等。普通投资者想要参与美股交易还是有诸多不便,也有很多限制。所以目前还是很不方便的,投资者还是多参与自己熟悉的投资品种。支付宝不能买b站股票。支付宝没有代理股票买卖权限。b站即哔哩哔哩,在美国NASDAQ证券交易所上市。所以投资者如果想买b站的话,就得开通美股账户。目前国内可以开通美股账户的有老虎证券、富途证券等。普通投资者想要参与美股交易还是有诸多不便,也有很多限制。所以目前还是很不方便的,投资者还是多参与自己熟悉的投资品种。
Create dataset wudao at scatter 2 with 30099 documents
[38350, 33591, 43368, 1272, 43861, 6038, 1654, 493, 43389, 3554, 33591, 43368, 1272, 43861, 6038, 1654, 4676, 746, 175, 341, 9427, 1272, 43861, 6038, 43359, 16210, 3554, 33591, 540, 4388, 757, 43359, 43442, 15152, 229, 926, 18466, 827, 22629, 9836, 183, 26150, 926, 18351, 1841, 685, 43601, 44365, 43359, 3554, 33591, 43368, 43601, 43636, 43601, 44365, 28120, 43680, 11413, 43359, 542, 1272, 43861, 43359, 95, 6131, 43384, 9188, 6123, 43359, 1272, 43861, 6038, 1654, 43359, 1759, 43399, 6131, 43384, 9188, 43405, 43601, 44365, 43361, 43373, 632, 9880, 389, 685, 1786, 43359, 1272, 6038, 48, 93, 1178, 44857, 43801, 43359, 187, 5835, 24849, 43317, 1135, 43359, 851, 6038, 116, 11650, 43361, 3554, 33591, 43368, 1272, 43861, 6038, 1654, 4676, 746, 175, 341, 9427, 1272, 43861, 6038, 43359, 16210, 3554, 33591, 540, 4388, 757, 43359, 43442, 15152, 229, 926, 18466, 827, 22629, 9836, 183, 26150, 926, 18351, 1841, 685, 43601, 44365, 43359, 3554, 33591, 43368, 43601, 43636, 43601, 44365, 28120, 43680, 11413, 43359, 542, 1272, 43861, 43359, 95, 6131, 43384, 9188, 6123, 43359, 1272, 43861, 6038, 1654, 43359, 1759, 43399, 6131, 43384, 9188, 43405, 43601, 44365, 43361, 43373, 632, 9880, 389, 685, 1786, 43359, 1272, 6038, 48, 93, 1178, 44857, 43801, 43359, 187, 5835, 24849, 43317, 1135, 43359, 851, 6038, 116, 11650, 43361]
51即刻有工资卡流水不足怎么办?51即刻有工资卡流水不足可以通过以下方法解决:1、工资卡流水,可以和51即刻有的工作人员联系,看是否能提供证明自己有稳定收入的凭证以及财力证明;2、如果是申请提额,51即刻有提单提额是三选一的,除了工资卡,还有信用卡和公积金可以选择,工资卡流水不足,试试用信用卡和公积金来提额。在银行或其他机构申请贷款,工资流水都是比较重要的凭据,建议每月定额存入资金,保证流水不要中断。51即刻有工资卡流水不足可以通过以下方法解决:1、工资卡流水,可以和51即刻有的工作人员联系,看是否能提供证明自己有稳定收入的凭证以及财力证明;2、如果是申请提额,51即刻有提单提额是三选一的,除了工资卡,还有信用卡和公积金可以选择,工资卡流水不足,试试用信用卡和公积金来提额。在银行或其他机构申请贷款,工资流水都是比较重要的凭据,建议每月定额存入资金,保证流水不要中断。
[43358, 4330, 44339, 45198, 8496, 643, 8, 43389, 2820, 4330, 8496, 6852, 4330, 44339, 45198, 43360, 8496, 43359, 4330, 8496, 6899, 643, 5953, 10672, 6467, 15259, 43359, 44466, 43572, 1135, 43410, 3279, 18131, 2820, 43359, 43442, 45214, 1467, 15945, 43359, 4273, 43359, 4330, 8496, 30968, 643, 5953, 9683, 43409, 6467, 15259, 43359, 43394, 1526, 45378, 44232, 19820, 2820, 43359, 43442, 45497, 1467, 15945, 43361, 4330, 855, 17969, 938, 43359, 5953, 6666, 2820, 772, 5332, 45214, 43359, 43727, 41934, 44466, 43572, 1135, 18131, 2820, 3466, 43359, 3050, 23998, 33002, 19029, 19915, 43384, 6266, 43361, 2820, 4330, 8496, 6852, 4330, 44339, 45198, 43360, 8496, 43359, 4330, 8496, 6899, 643, 5953, 10672, 6467, 15259, 43359, 44466, 43572, 1135, 43410, 3279, 18131, 2820, 43359, 43442, 45214, 1467, 15945, 43359, 4273, 43359, 4330, 8496, 30968, 643, 5953, 9683, 43409, 6467, 15259, 43359, 43394, 1526, 45378, 44232, 19820, 2820, 43359, 43442, 45497, 1467, 15945, 43361, 4330, 855, 17969, 938, 43359, 5953, 6666, 2820, 772, 5332, 45214, 43359, 43727, 41934, 44466, 43572, 1135, 18131, 2820, 3466, 43359, 3050, 23998, 33002, 19029, 19915, 43384, 6266, 43361]
融资融券余额说明什么?股票融资余额指的是融资融券的余额,融资余额越高说明投资者看好后续走势,借入资金后大量的买入股票,看涨情绪较强,相反,融资余额越低说明投资者不看好后续走势,会大量抛售手中的股票,看跌情绪较强。融资是一种杠杆交易,投资者预计股票未来会上涨,向证券公司借入资金买入股票的行为,并在约定的期限内偿还本金和利息。股票融资余额指的是融资融券的余额,融资余额越高说明投资者看好后续走势,借入资金后大量的买入股票,看涨情绪较强,相反,融资余额越低说明投资者不看好后续走势,会大量抛售手中的股票,看跌情绪较强。融资是一种杠杆交易,投资者预计股票未来会上涨,向证券公司借入资金买入股票的行为,并在约定的期限内偿还本金和利息。
[20074, 632, 2369, 1786, 9250, 2369, 26658, 1786, 43655, 2837, 3320, 646, 1227, 43389, 180, 23533, 43913, 2602, 43367, 308, 693, 44158, 44090, 1118, 43384, 338, 38500, 5550, 278, 43371, 43361, 2172, 3522, 308, 12837, 3508, 43359, 43368, 1953, 8228, 43945, 44565, 43384, 9950, 43361, 308, 7648, 438, 18773, 545, 43359, 2444, 3519, 43359, 43368, 44038, 43568, 19029, 1786, 43456, 43858, 3008, 43359, 43812, 43491, 43966, 4891, 6130, 597, 30410, 7603, 43360, 124, 1139, 92, 7751, 1089, 2369, 35191, 43567, 1977, 43359, 400, 12180, 632, 3232, 7114, 6568, 926, 43361, 43478, 44243, 1402, 43430, 43764, 43789, 43432, 5982, 43359, 13659, 799, 38413, 1359, 5576, 43361, 2487, 43663, 43478, 44243, 1402, 4454, 43595, 632, 43359, 185, 19029, 1786, 43456, 43858, 43360, 6438, 43361, 632, 216, 5729, 114, 535, 43361]
大连银行住房贷款一手住房按揭贷款该产品的适用客户有哪些?18-70周岁的、具有有效居留身份和完全民事行为能力的自然人。在中国境内具有常住户口,有准确详细的住址和联系方式。具有稳定的职业和经济收入,信用良好,有按期偿还贷款本息的能力,且月供金额不超过家庭可支配收入总额的50%。已经签署购买住房的合同或协议,能够出具银行认可的首付款证明。所购房屋“五证”齐全,能够在房地产交易市场登记备案。同意将所购房屋抵押给银行,作为偿还贷款本息的担保。银行要求提供的其他材料。
[12755, 43781, 236, 692, 1784, 692, 103, 10027, 43389, 4364, 43460, 7, 43359, 238, 682, 2674, 692, 43359, 13565, 1235, 8325, 1459, 692, 703, 43397, 2674, 43598, 44009, 43367, 4450, 43367, 2674, 14329, 43396, 43477, 43359, 8168, 43781, 30759, 692, 1784, 43359, 1216, 74, 18635, 43361, 24653, 1082, 1504, 43705, 5516, 2842, 43422, 6064, 1082, 1504, 74, 18635, 43359, 28744, 514, 692, 43470, 1833, 43410, 43359, 43415, 2336, 43422, 1504, 43705, 74, 692, 703, 1459, 18635, 43361, 43398, 192, 43781, 236, 1784, 682, 32109, 43359, 43511, 3951, 29939, 5989, 682, 32109, 273, 2674, 1095, 692, 43384, 2674, 12155, 236, 142, 191, 682, 2674, 1095, 40330, 43598, 44009, 43384, 4450, 27503, 274, 682, 2674, 1095, 2792, 3075, 9940, 43360, 43359, 43511, 2674, 1082, 842, 7, 3075, 9940, 43360, 43359, 43511, 7236, 692, 1784, 2674, 1082, 142, 2792, 5279, 2442, 1444, 2388, 43360, 43361, 43314, 43359, 43511, 105, 1235, 692, 1784, 346, 13278, 451, 43361, 2120, 43359, 28, 43781, 5490, 43359, 7886, 43386, 44852, 5490, 43359, 47, 43359, 49, 981, 12590, 43360, 43361, 36, 35635, 788, 126, 400, 27112, 525, 9075, 1160, 43360, 692, 43359, 47, 187, 7, 44111, 253, 3127, 692, 4303, 43480, 1089, 2679, 692, 43359, 3242, 229, 2165, 1160, 43361]
旅游买两个保险公司的保险产品可以吗? 您好!可以,对于旅游意外保险,只要是符合条款内的保险责任(意外身故、残疾、意外津贴)等,不管是买多少个保险公司的,都可以进行赔付。但是对于医疗费用型一般是仅仅对发生的医疗费用进行赔付,不过现在新的保险法修改后,也允许对费用型进行保险责任内的赔付。能同时买两个公司的旅游意外险,但要注意的问题是:1.旅游意外险包括意外伤害保险和意外医疗保险两个部分2.旅游意外伤害又分为身故和残疾两个方面3.旅游意外伤害是可以重复报销的,但意外医疗是不可以重复报销的,但多家保险公司的意外医疗部分是可以起到互相补充的作用的。当然可以,但应该符合保险公司的相关投保规定。实际上,因为买得多,保险公司就赚得多,所以,他们应该是很高兴的。但是买保险一定要选择能够使自己得到全面的保障的保险,所以建议可以拿其中一份保险的钱去购买其他的保险,给自己提供更多的保障。
[5667, 43428, 632, 6131, 13078, 43454, 43389, 43409, 685, 43389, 43693, 632, 6131, 13078, 43490, 26036, 11080, 1419, 183, 108, 43607, 43587, 411, 446, 43359, 10966, 685, 327, 130, 1045, 13078, 6131, 43359, 348, 746, 21046, 9427, 789, 632, 43853, 45669, 15741, 43861, 557, 4881, 43623, 43861, 43359, 513, 3853, 685, 43359, 12055, 15741, 43861, 4157, 43359, 43861, 44365, 12446, 43861, 4429, 93, 14583, 43359, 13078, 8975, 43402, 23707, 43359, 43812, 1248, 43392, 43403, 131, 43717, 36014, 36059, 632, 43407, 15741, 108, 42160, 15390, 43373, 3534, 26687, 1182, 685, 43359, 1423, 43379, 43861, 43746, 43861, 5302, 685, 43359, 15741, 43861, 13078, 8975, 43402, 43717, 289, 43359, 35753, 43860, 43708, 43359, 43398, 43421, 43861, 13078, 6899, 43361, 2263, 4682, 13323, 15741, 43861, 27874, 19479, 1182, 685, 43359, 2865, 508, 6899, 43359, 43421, 43861, 43454, 44365, 1990, 4927, 6292, 43361, 639, 685, 43403, 43402, 43717, 2615, 4682, 13323, 15741, 43861, 43359, 2865, 508, 26330, 4, 43717, 289, 43361]
哪家银行信用卡额度高?好申请?各银行信用卡额度与申请的卡片等级以及个人资信条件有关,如果想申请容易通过的高额度信用卡,推荐以下几款:1、交通银行优逸白金卡属于小白金卡,适合年轻人申请,因为是白金卡级别,卡额度和卡权益比较给力,额度一般在5万元以上,且最高可到30万。2、中信银行i白金个人税前月薪在5000元以上即可申请,还可以以卡办卡快捷申请,白金卡额度一般在5万以上,经济实力越强,能下卡额度越高。3、平安车主白金卡有车一族即可申请,车辆价值越高,下卡高额度的几率越大。想要申请到5万以上的平安车主白金卡,车辆价值最好在20万以上。
[8657, 38461, 43389, 38461, 79, 43774, 43623, 43367, 44213, 43367, 47264, 43367, 49285, 43367, 0, 43367, 0, 43367, 0, 43367, 49934, 43477, 44017, 43493, 1743, 1788, 43359, 253, 2560, 43367, 14919, 43367, 41539, 43384, 49285, 43623, 43362, 334, 6141, 93, 4893, 938, 2319, 43361, 5953, 4676, 4801, 39593, 334, 38461, 9427, 9729, 938, 43383, 112, 9729, 938, 2560, 43384, 14919, 6139, 43359, 79, 130, 1089, 43623, 43367, 44213, 43751, 43359, 43623, 43367, 44213, 44684, 22375, 43367, 44213, 13048, 43477, 18351, 938, 44492, 2560, 43383, 855, 43659, 632, 229, 5122, 43359, 3310, 38461, 43377, 7813, 3508, 43359, 20, 130, 43473, 2544, 5470, 43588, 43723, 43650, 43359, 922, 130, 20702, 39593, 334, 2560, 23337, 7486, 938, 43383, 5079, 7486, 4795, 43410, 43359, 7, 938, 43379, 38461, 43377, 15708, 6429, 43523, 10916, 43361, 38461, 79, 43774, 43623, 43367, 44213, 43367, 47264, 43367, 49285, 43367, 0, 43367, 0, 43367, 0, 43367, 49934, 43477, 44017, 43493, 1743, 1788, 43359, 253, 2560, 43367, 14919, 43367, 41539, 43384, 49285, 43623, 43362, 334, 6141, 93, 4893, 938, 2319, 43361, 5953, 4676, 4801, 39593, 334, 38461, 9427, 9729, 938, 43383, 112, 9729, 938, 2560, 43384, 14919, 6139, 43359, 79, 130, 1089, 43623, 43367, 44213, 43751, 43359, 43623, 43367, 44213, 44684, 22375, 43367, 44213, 13048, 43477, 18351, 938, 44492, 2560, 43383, 855, 43659, 632, 229, 5122, 43359, 3310, 38461, 43377, 7813, 3508, 43359, 20, 130, 43473, 2544, 5470, 43588, 43723, 43650, 43359, 922, 130, 20702, 39593, 334, 2560, 23337, 7486, 938, 43383, 5079, 7486, 4795, 43410, 43359, 7, 938, 43379, 38461, 43377, 15708, 6429, 43523, 10916, 43361]
什么是贵金属?贵金属主要指金、银、铂、钯、 ⁇ 、 ⁇ 、 ⁇ 、铱等八种金属元素,其中黄金、白银、铂金和钯金是投资市场上比较常见的交易品种。投资者可以通过三种方式来投资贵金属:1、实物交易:一般实物交易黄金和白银较多,主要通过购买金、银条,金、银币和金、银饰品等;2、交易纸黄金:是一种由银行提供的服务,是以贵金属为单位的户口,不是通过实物的买卖及交收,而是通过记账方式来投资黄金;3、期货交易:开通期货账户后,可以交易以贵金属为标的的标准化合约。贵金属主要指金、银、铂、钯、 ⁇ 、 ⁇ 、 ⁇ 、铱等八种金属元素,其中黄金、白银、铂金和钯金是投资市场上比较常见的交易品种。投资者可以通过三种方式来投资贵金属:1、实物交易:一般实物交易黄金和白银较多,主要通过购买金、银条,金、银币和金、银饰品等;2、交易纸黄金:是一种由银行提供的服务,是以贵金属为单位的户口,不是通过实物的买卖及交收,而是通过记账方式来投资黄金;3、期货交易:开通期货账户后,可以交易以贵金属为标的的标准化合约。
[35476, 20193, 43410, 6413, 7, 9940, 43689, 43389, 585, 43359, 19, 1077, 20193, 1037, 5260, 1061, 6413, 43359, 43812, 1040, 18239, 305, 43359, 43946, 21865, 18239, 43359, 3953, 43359, 20193, 3424, 9940, 43705, 103, 43359, 922, 29285, 43705, 103, 43359, 379, 1235, 43417, 44094, 411, 43359, 135, 440, 301, 8716, 692, 10515, 18239, 43359, 1878, 735, 524, 6886, 22250, 1504, 74, 9940, 43359, 562, 43359, 19, 6413, 197, 422, 43450, 43799, 43397, 311, 47308, 44619, 44533, 43477, 44162, 43410, 371, 3519, 43396, 22339, 6413, 43359, 43946, 9228, 20193, 18239, 305, 43359, 418, 301, 18635, 43361, 585, 43359, 19, 1077, 20193, 1037, 5260, 1061, 6413, 43359, 43812, 1040, 18239, 305, 43359, 43946, 21865, 18239, 43359, 3953, 43359, 20193, 3424, 9940, 43705, 103, 43359, 922, 29285, 43705, 103, 43359, 379, 1235, 43417, 44094, 411, 43359, 135, 440, 301, 8716, 692, 10515, 18239, 43359, 1878, 735, 524, 6886, 22250, 1504, 74, 9940, 43359, 562, 43359, 19, 6413, 197, 422, 43450, 43799, 43397, 311, 47308, 44619, 44533, 43477, 44162, 43410, 371, 3519, 43396, 22339, 6413, 43359, 43946, 9228, 20193, 18239, 305, 43359, 418, 301, 18635, 43361]
买了重疾险后住院可以报销吗?首先,如果是因为重疾险合同约定疾病住院,且满足理赔标准,则可以获得理赔,其次,重疾险并非报销型产品,而是给付型产品,只要符合出险条件,那么就可以获得一次性保险金的理赔,而不是按照实际花费的医疗费用进行报销,当然,如果住院只是因此小病(比如阑尾炎等预后效果良好)等原因住院,则不符合重疾险理赔标准,无法获得赔付。首先,如果是因为重疾险合同约定疾病住院,且满足理赔标准,则可以获得理赔,其次,重疾险并非报销型产品,而是给付型产品,只要符合出险条件,那么就可以获得一次性保险金的理赔,而不是按照实际花费的医疗费用进行报销,当然,如果住院只是因此小病(比如阑尾炎等预后效果良好)等原因住院,则不符合重疾险理赔标准,无法获得赔付。
[5195, 44803, 692, 24, 43781, 43389, 44026, 44803, 692, 13278, 43392, 723, 43430, 43407, 44026, 44803, 43602, 43432, 1437, 13278, 496, 43359, 43562, 692, 5575, 12929, 43639, 11297, 43367, 5811, 34231, 11297, 43549, 3196, 2359, 11297, 43549, 1954, 11297, 43360, 16887, 43371, 1431, 43359, 33081, 22257, 13278, 1639, 43361, 610, 43359, 3732, 26981, 290, 43377, 1235, 44136, 43602, 7488, 1487, 43367, 16643, 43367, 4092, 43367, 495, 43781, 43359, 43511, 2999, 43371, 82, 43781, 43412, 44126, 43361, 44026, 44803, 692, 13278, 43392, 723, 43430, 43407, 44026, 44803, 43602, 43432, 1437, 13278, 496, 43359, 43562, 692, 5575, 12929, 43639, 11297, 43367, 5811, 34231, 11297, 43549, 3196, 2359, 11297, 43549, 1954, 11297, 43360, 16887, 43371, 1431, 43359, 33081, 22257, 13278, 1639, 43361, 610, 43359, 3732, 26981, 290, 43377, 1235, 44136, 43602, 7488, 1487, 43367, 16643, 43367, 4092, 43367, 495, 43781, 43359, 43511, 2999, 43371, 82, 43781, 43412, 44126, 43361]
龙惠保险怎么买?龙惠保险投保可关注“i龙惠保”官方投保平台,被保险人是黑龙江省直医保、哈尔滨城乡居民医保/城镇职工医保/铁路医保的参保人就行,没有其他额外的投保限制。另外,这款医疗险支持为符合承保条件的本人、配偶、子女、父母买,但同一人不能买多份。龙惠保险投保可关注“i龙惠保”官方投保平台,被保险人是黑龙江省直医保、哈尔滨城乡居民医保/城镇职工医保/铁路医保的参保人就行,没有其他额外的投保限制。另外,这款医疗险支持为符合承保条件的本人、配偶、子女、父母买,但同一人不能买多份。
[43358, 4904, 772, 12690, 692, 43368, 11201, 1160, 43689, 4364, 43460, 7151, 43587, 44580, 4904, 772, 111, 31786, 692, 11446, 1160, 111, 43359, 43441, 229, 131, 43493, 11201, 1160, 43359, 44381, 106, 7668, 43373, 2635, 43568, 43410, 13418, 286, 43812, 2682, 9682, 131, 43493, 11201, 410, 354, 43359, 25838, 43454, 44365, 1160, 43359, 6205, 2441, 380, 43361, 43444, 13278, 43371, 2635, 43568, 43410, 43598, 44009, 43359, 43499, 44663, 43567, 43855, 44558, 1037, 23998, 11201, 43397, 1235, 1037, 5260, 65, 43392, 44163, 43723, 7121, 1504, 43359, 106, 1615, 43360, 1160, 4649, 43361, 289, 4127, 462, 4904, 772, 12690, 692, 4230, 11201, 1160, 461, 320, 43359, 18866, 20007, 1957, 33704, 43361]
守护未来少儿保险有重疾保障吗 您好!招商信诺守护未来教育年金保险不仅仅是保障教育,还提供30种重疾保障,若孩子不幸在等待期后初次发生且首次确诊30种重疾任何一种,可获得高额保障,给孩子更好的治疗。如投保人等待期后身故,全残或首患合同约定的重疾(符合合同约定),可免交剩余费用,孩子享受的保障不变。以上便是关于守护未来少儿保险是否有重疾保障的问题回答,希望可以给您带来参考价值。
[43358, 26817, 43648, 44791, 14383, 3294, 5872, 3441, 99, 45140, 43648, 43389, 26817, 43648, 44791, 14383, 43366, 530, 5872, 43359, 632, 3509, 2086, 45445, 40884, 1775, 43361, 43471, 14383, 781, 2053, 43359, 439, 17420, 43365, 9782, 43359, 135, 632, 36034, 45140, 43648, 43361, 36, 9160, 300, 43359, 379, 632, 262, 439, 7110, 14383, 43365, 9782, 43359, 36034, 45140, 43648, 43359, 422, 43380, 2053, 1168, 1697, 6579, 5606, 5077, 43361, 154, 43648, 44791, 14383, 26309, 43359, 22898, 1361, 43378, 43394, 42475, 43359, 268, 43486, 685, 15281, 641, 115, 43359, 1850, 418, 130, 2868, 43360, 43361, 26817, 43648, 44791, 14383, 43366, 530, 5872, 43359, 632, 3509, 2086, 45445, 40884, 1775, 43361, 43471, 14383, 781, 2053, 43359, 439, 17420, 43365, 9782, 43359, 135, 632, 36034, 45140, 43648, 43361, 36, 9160, 300, 43359, 379, 632, 262, 439, 7110, 14383, 43365, 9782, 43359, 36034, 45140, 43648, 43359, 422, 43380, 2053, 1168, 1697, 6579, 5606, 5077, 43361, 154, 43648, 44791, 14383, 26309, 43359, 22898, 1361, 43378, 43394, 42475, 43359, 268, 43486, 685, 15281, 641, 115, 43359, 1850, 418, 130, 2868, 43360, 43361]
工商银行车贷逾期多久之内没事不会拖车?工商银行车贷逾期1个月之内,银行只会采取催收的措施。而逾期超过一个月,用户仍旧不还款,那么银行就有可能拖车。但是实际情况来说,只要银行认为用户恶意逾期不还款,就有可能拖车,因此这一个月的时间差不多可以说是最后的期限。而且车贷逾期不还,征信报告中会记录下来,以后想申请信贷业务的话,基本上无法通过审核的。工商银行车贷逾期1个月之内,银行只会采取催收的措施。而逾期超过一个月,用户仍旧不还款,那么银行就有可能拖车。但是实际情况来说,只要银行认为用户恶意逾期不还款,就有可能拖车,因此这一个月的时间差不多可以说是最后的期限。而且车贷逾期不还,征信报告中会记录下来,以后想申请信贷业务的话,基本上无法通过审核的。
Dataset document count 28563, token count 5355563, non sentence start0.0
Dataset document count 1505, token count 285477, non sentence start0.0
Dataset document count 30, token count 5576, non sentence start0.0
BERT prob 0.4, gap sent prob 0.3, GPT prob 0.3, infill prob 0.5
generation min ratio 0.25, block ratio 0.15, gap sent ratio 0.15
block length distribution [0.14936120510359185, 0.22404180765538775, 0.22404180765538775, 0.16803135574154085, 0.10081881344492458, 0.05040940672246224, 0.02160403145248382, 0.008101511794681432, 0.002700503931560479, 0.0008101511794681439, 0.00022095032167312998, 5.523758041828258e-05, 1.2747133942680616e-05, 2.7315287020029775e-06, 5.463057404005949e-07, 1.0243232632511163e-07, 1.807629288090209e-08, 3.0127154801503496e-09, 4.756919179184761e-10, 7.135378768777153e-11, 1.01933982411102e-11, 1.3900088510604783e-12, 1.8130550231223652e-13, 2.26631877890296e-14, 2.719582534683569e-15, 3.1379798477117986e-16, 3.486644275235373e-17, 3.735690294894986e-18, 3.8645072016155465e-19, 3.864507201615528e-20, 3.739845678982777e-21, 3.5061053240463625e-22, 3.18736847640571e-23, 2.8123839497698246e-24, 2.410614814088421e-25, 2.0088456784069862e-26, 1.6287937933030137e-27, 1.285889836818143e-28, 9.89146028321656e-30]
block mask prob 0.1, context mask ratio 0.0
BERT prob 0.4, gap sent prob 0.3, GPT prob 0.3, infill prob 0.5
generation min ratio 0.25, block ratio 0.15, gap sent ratio 0.15
block length distribution [0.14936120510359185, 0.22404180765538775, 0.22404180765538775, 0.16803135574154085, 0.10081881344492458, 0.05040940672246224, 0.02160403145248382, 0.008101511794681432, 0.002700503931560479, 0.0008101511794681439, 0.00022095032167312998, 5.523758041828258e-05, 1.2747133942680616e-05, 2.7315287020029775e-06, 5.463057404005949e-07, 1.0243232632511163e-07, 1.807629288090209e-08, 3.0127154801503496e-09, 4.756919179184761e-10, 7.135378768777153e-11, 1.01933982411102e-11, 1.3900088510604783e-12, 1.8130550231223652e-13, 2.26631877890296e-14, 2.719582534683569e-15, 3.1379798477117986e-16, 3.486644275235373e-17, 3.735690294894986e-18, 3.8645072016155465e-19, 3.864507201615528e-20, 3.739845678982777e-21, 3.5061053240463625e-22, 3.18736847640571e-23, 2.8123839497698246e-24, 2.410614814088421e-25, 2.0088456784069862e-26, 1.6287937933030137e-27, 1.285889836818143e-28, 9.89146028321656e-30]
block mask prob 0.1, context mask ratio 0.0
BERT prob 0.4, gap sent prob 0.3, GPT prob 0.3, infill prob 0.5
generation min ratio 0.25, block ratio 0.15, gap sent ratio 0.15
block length distribution [0.14936120510359185, 0.22404180765538775, 0.22404180765538775, 0.16803135574154085, 0.10081881344492458, 0.05040940672246224, 0.02160403145248382, 0.008101511794681432, 0.002700503931560479, 0.0008101511794681439, 0.00022095032167312998, 5.523758041828258e-05, 1.2747133942680616e-05, 2.7315287020029775e-06, 5.463057404005949e-07, 1.0243232632511163e-07, 1.807629288090209e-08, 3.0127154801503496e-09, 4.756919179184761e-10, 7.135378768777153e-11, 1.01933982411102e-11, 1.3900088510604783e-12, 1.8130550231223652e-13, 2.26631877890296e-14, 2.719582534683569e-15, 3.1379798477117986e-16, 3.486644275235373e-17, 3.735690294894986e-18, 3.8645072016155465e-19, 3.864507201615528e-20, 3.739845678982777e-21, 3.5061053240463625e-22, 3.18736847640571e-23, 2.8123839497698246e-24, 2.410614814088421e-25, 2.0088456784069862e-26, 1.6287937933030137e-27, 1.285889836818143e-28, 9.89146028321656e-30]
block mask prob 0.1, context mask ratio 0.0
building GPT2 model ...
 > number of parameters on model parallel rank 0: 355659776
DeepSpeed is enabled.
[2022-01-12 08:57:46,627] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed info: version=0.5.9+317400e, git-hash=317400e, git-branch=master
[2022-01-12 08:57:46,635] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed groups using mpu
[2022-01-12 08:57:46,635] [INFO] [logging.py:69:log_dist] [Rank 0] Initializing deepspeed groups with model parallel size 1, expert parallel size 1, and data parallel size 3
[2022-01-12 08:57:46,778] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0, 1, 2]
[2022-01-12 08:57:46,778] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]
[2022-01-12 08:57:46,789] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert parallel process group with ranks: [1]
[2022-01-12 08:57:46,789] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert parallel process group with ranks: [2]
glm_dist16:26190:26348 [2] NCCL INFO Trees [0] -1/-1/-1->2->1 [1] -1/-1/-1->2->1
glm_dist16:26188:26347 [0] NCCL INFO Channel 00/02 :    0   1   2
glm_dist16:26189:26349 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
glm_dist16:26188:26347 [0] NCCL INFO Channel 01/02 :    0   1   2
glm_dist16:26190:26348 [2] NCCL INFO Setting affinity for GPU 2 to 3ffff0,0003ffff
glm_dist16:26189:26349 [1] NCCL INFO Setting affinity for GPU 1 to 3ffff0,0003ffff
glm_dist16:26188:26347 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
glm_dist16:26188:26347 [0] NCCL INFO Setting affinity for GPU 0 to 3ffff0,0003ffff
glm_dist16:26189:26349 [1] NCCL INFO Channel 00 : 1[1c000] -> 2[1d000] via P2P/IPC
glm_dist16:26188:26347 [0] NCCL INFO Channel 00 : 0[1b000] -> 1[1c000] via P2P/IPC
glm_dist16:26190:26348 [2] NCCL INFO Channel 00 : 2[1d000] -> 0[1b000] via P2P/IPC
glm_dist16:26189:26349 [1] NCCL INFO Channel 01 : 1[1c000] -> 2[1d000] via P2P/IPC
glm_dist16:26188:26347 [0] NCCL INFO Channel 01 : 0[1b000] -> 1[1c000] via P2P/IPC
glm_dist16:26190:26348 [2] NCCL INFO Channel 01 : 2[1d000] -> 0[1b000] via P2P/IPC
glm_dist16:26189:26349 [1] NCCL INFO Connected all rings
glm_dist16:26188:26347 [0] NCCL INFO Connected all rings
glm_dist16:26190:26348 [2] NCCL INFO Connected all rings
glm_dist16:26190:26348 [2] NCCL INFO Channel 00 : 2[1d000] -> 1[1c000] via P2P/IPC
glm_dist16:26190:26348 [2] NCCL INFO Channel 01 : 2[1d000] -> 1[1c000] via P2P/IPC
glm_dist16:26189:26349 [1] NCCL INFO Channel 00 : 1[1c000] -> 0[1b000] via P2P/IPC
glm_dist16:26189:26349 [1] NCCL INFO Channel 01 : 1[1c000] -> 0[1b000] via P2P/IPC
glm_dist16:26190:26348 [2] NCCL INFO Connected all trees
glm_dist16:26190:26348 [2] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/512
glm_dist16:26190:26348 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
glm_dist16:26188:26347 [0] NCCL INFO Connected all trees
glm_dist16:26188:26347 [0] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/512
glm_dist16:26188:26347 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
glm_dist16:26189:26349 [1] NCCL INFO Connected all trees
glm_dist16:26189:26349 [1] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/512
glm_dist16:26189:26349 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
glm_dist16:26189:26349 [1] NCCL INFO comm 0x7f4b18006a20 rank 1 nranks 3 cudaDev 1 busId 1c000 - Init COMPLETE
glm_dist16:26190:26348 [2] NCCL INFO comm 0x7faa30006a20 rank 2 nranks 3 cudaDev 2 busId 1d000 - Init COMPLETE
glm_dist16:26188:26347 [0] NCCL INFO comm 0x7fb260006a20 rank 0 nranks 3 cudaDev 0 busId 1b000 - Init COMPLETE
glm_dist16:26188:26188 [0] NCCL INFO Launch mode Parallel
[2022-01-12 08:57:48,752] [INFO] [engine.py:277:__init__] DeepSpeed Flops Profiler Enabled: False
[2022-01-12 08:57:48,832] [INFO] [engine.py:1107:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer
[2022-01-12 08:57:48,847] [INFO] [engine.py:1115:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam
[2022-01-12 08:57:48,847] [INFO] [logging.py:69:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
[2022-01-12 08:57:49,058] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam
[2022-01-12 08:57:49,059] [INFO] [engine.py:807:_configure_lr_scheduler] DeepSpeed using client LR scheduler
[2022-01-12 08:57:49,059] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2022-01-12 08:57:49,059] [INFO] [logging.py:69:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0004, 0.0004], mom=[[0.9, 0.98], [0.9, 0.98]]
[2022-01-12 08:57:49,060] [INFO] [config.py:1058:print] DeepSpeedEngine configuration:
[2022-01-12 08:57:49,061] [INFO] [config.py:1062:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2022-01-12 08:57:49,061] [INFO] [config.py:1062:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-01-12 08:57:49,061] [INFO] [config.py:1062:print]   amp_enabled .................. False
[2022-01-12 08:57:49,061] [INFO] [config.py:1062:print]   amp_params ................... False
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": null, 
    "exps_dir": null, 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   bfloat16_enabled ............. False
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   checkpoint_tag_validation_enabled  True
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   checkpoint_tag_validation_fail  False
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   communication_data_type ...... None
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   curriculum_enabled ........... False
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   curriculum_params ............ False
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   dataloader_drop_last ......... False
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   disable_allgather ............ False
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   dump_state ................... False
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   dynamic_loss_scale_args ...... {'init_scale': 4294967296, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}
[2022-01-12 08:57:49,062] [INFO] [config.py:1062:print]   eigenvalue_enabled ........... False
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   eigenvalue_gas_boundary_resolution  1
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   eigenvalue_layer_num ......... 0
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   eigenvalue_max_iter .......... 100
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   eigenvalue_stability ......... 1e-06
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   eigenvalue_tol ............... 0.01
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   eigenvalue_verbose ........... False
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   elasticity_enabled ........... False
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   fp16_enabled ................. True
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   fp16_master_weights_and_gradients  False
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   fp16_mixed_quantize .......... False
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   global_rank .................. 0
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   gradient_accumulation_steps .. 1
[2022-01-12 08:57:49,063] [INFO] [config.py:1062:print]   gradient_clipping ............ 1.0
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   gradient_predivide_factor .... 1.0
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   initial_dynamic_scale ........ 4294967296
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   loss_scale ................... 0
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   memory_breakdown ............. False
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   optimizer_legacy_fusion ...... False
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   optimizer_name ............... adam
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   optimizer_params ............. {'lr': 0.0004, 'weight_decay': 0.01, 'betas': [0.9, 0.98], 'eps': 1e-06}
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   pld_enabled .................. False
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   pld_params ................... False
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   prescale_gradients ........... False
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   quantize_change_rate ......... 0.001
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   quantize_groups .............. 1
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   quantize_offset .............. 1000
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   quantize_period .............. 1000
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   quantize_rounding ............ 0
[2022-01-12 08:57:49,064] [INFO] [config.py:1062:print]   quantize_start_bits .......... 16
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   quantize_target_bits ......... 8
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   quantize_training_enabled .... False
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   quantize_type ................ 0
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   quantize_verbose ............. False
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   scheduler_name ............... None
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   scheduler_params ............. None
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   sparse_attention ............. None
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   sparse_gradients_enabled ..... False
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   steps_per_print .............. 100
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   tensorboard_enabled .......... False
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   tensorboard_job_name ......... DeepSpeedJobName
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   tensorboard_output_path ...... 
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   train_batch_size ............. 96
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   train_micro_batch_size_per_gpu  32
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   use_quantizer_kernel ......... False
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   wall_clock_breakdown ......... False
[2022-01-12 08:57:49,065] [INFO] [config.py:1062:print]   world_size ................... 3
[2022-01-12 08:57:49,066] [INFO] [config.py:1062:print]   zero_allow_untested_optimizer  False
[2022-01-12 08:57:49,066] [INFO] [config.py:1062:print]   zero_config .................. {
    "stage": 0, 
    "contiguous_gradients": true, 
    "reduce_scatter": true, 
    "reduce_bucket_size": 5.000000e+08, 
    "allgather_partitions": true, 
    "allgather_bucket_size": 5.000000e+08, 
    "overlap_comm": false, 
    "load_from_fp32_weights": true, 
    "elastic_checkpoint": true, 
    "offload_param": null, 
    "offload_optimizer": null, 
    "sub_group_size": 1.000000e+09, 
    "prefetch_bucket_size": 5.000000e+07, 
    "param_persistence_threshold": 1.000000e+05, 
    "max_live_parameters": 1.000000e+09, 
    "max_reuse_distance": 1.000000e+09, 
    "gather_fp16_weights_on_model_save": false, 
    "ignore_unused_parameters": true, 
    "round_robin_gradients": false, 
    "legacy_stage1": false
}
[2022-01-12 08:57:49,066] [INFO] [config.py:1062:print]   zero_enabled ................. False
[2022-01-12 08:57:49,066] [INFO] [config.py:1062:print]   zero_optimization_stage ...... 0
[2022-01-12 08:57:49,066] [INFO] [config.py:1064:print]   json = {
    "train_micro_batch_size_per_gpu": 32, 
    "gradient_accumulation_steps": 1, 
    "steps_per_print": 100, 
    "gradient_clipping": 1.0, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "loss_scale_window": 1000, 
        "hysteresis": 2, 
        "min_loss_scale": 1
    }, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.0004, 
            "weight_decay": 0.01, 
            "betas": [0.9, 0.98], 
            "eps": 1e-06
        }
    }, 
    "activation_checkpointing": {
        "partition_activations": false, 
        "contiguous_memory_optimization": false
    }, 
    "wall_clock_breakdown": false
}
learning rate decaying style cosine, ratio 10.0
WARNING: could not find the metadata file ../model_save/checkpoints/latest_checkpointed_iteration.txt 
    will not load any checkpoints and will start from random
Pretrain GPT2 model
arguments:
  transformer_xl ............... False
  pretrained_bert .............. False
  encoder_decoder .............. False
  attention_dropout ............ 0.1
  num_attention_heads .......... 16
  hidden_size .................. 1024
  intermediate_size ............ None
  num_layers ................... 24
  layernorm_epsilon ............ 1e-05
  hidden_dropout ............... 0.1
  output_dropout ............... 0.1
  max_position_embeddings ...... 1024
  vocab_size ................... 50048
  deep_init .................... False
  make_vocab_size_divisible_by . 128
  cpu_optimizer ................ False
  cpu_torch_adam ............... False
  fp16 ......................... True
  fp32_embedding ............... False
  fp32_layernorm ............... False
  fp32_tokentypes .............. False
  fp32_allreduce ............... False
  hysteresis ................... 2
  loss_scale ................... None
  loss_scale_window ............ 1000
  min_scale .................... 1
  attention_scale .............. 1.0
  experiment_name .............. checkpoints
  batch_size ................... 32
  gradient_accumulation_steps .. 1
  weight_decay ................. 0.01
  checkpoint_activations ....... True
  checkpoint_num_layers ........ 1
  deepspeed_activation_checkpointing  True
  epochs ....................... None
  clip_grad .................... 1.0
  train_iters .................. 250000000
  label_smoothing .............. 0.0
  log_interval ................. 50
  summary_dir .................. 
  seed ......................... 1234
  reset_position_ids ........... False
  reset_attention_mask ......... False
  lr_decay_iters ............... 200000
  lr_decay_style ............... cosine
  lr_decay_ratio ............... 0.1
  lr ........................... 0.0004
  warmup ....................... 0.04
  switch_linear ................ False
  save ......................... ../model_save/checkpoints/checkpoints
  new_save_directory ........... False
  save_epoch ................... 1
  save_interval ................ 2000
  no_save_optim ................ False
  no_save_rng .................. False
  load ......................... ../model_save/checkpoints/
  no_load_optim ................ False
  no_load_rng .................. False
  no_load_lr_scheduler ......... False
  no_deepspeed_load ............ False
  finetune ..................... False
  resume_dataloader ............ True
  distributed_backend .......... nccl
  DDP_impl ..................... torch
  local_rank ................... 0
  block_lm ..................... True
  masked_lm .................... False
  bert_prob .................... 0.4
  gpt_infill_prob .............. 0.5
  gpt_min_ratio ................ 0.25
  gap_sentence_prob ............ 0.3
  gap_sentence_ratio ........... 0.15
  avg_block_length ............. 3
  short_seq_prob ............... 0.02
  single_span_prob ............. 0.0
  task_mask .................... True
  no_shuffle_block ............. False
  no_block_position ............ False
  sentinel_token ............... False
  block_mask_prob .............. 0.1
  context_mask_ratio ........... 0.0
  random_position .............. False
  eval_batch_size .............. None
  eval_iters ................... 100
  eval_interval ................ 1000
  eval_epoch ................... 1
  eval_seq_length .............. None
  eval_max_preds_per_seq ....... None
  overlapping_eval ............. 32
  temperature .................. 1.0
  top_p ........................ 0.0
  top_k ........................ 0
  out_seq_length ............... 256
  num_beams .................... 1
  length_penalty ............... 0.0
  no_repeat_ngram_size ......... 0
  min_tgt_length ............... 0
  select_topk .................. False
  blank_maskratio .............. 0.1
  model_parallel_size .......... 1
  shuffle ...................... False
  filter_english ............... False
  train_data ................... ['wudao']
  valid_data ................... None
  test_data .................... None
  data_dir ..................... None
  input_data_sizes_file ........ sizes.txt
  delim ........................ ,
  text_key ..................... sentence
  eval_text_key ................ None
  split ........................ 949,50,1
  no_lazy_loader ............... True
  half_lazy_loader ............. False
  loader_scatter ............... 4
  loose_json ................... False
  presplit_sentences ........... False
  num_workers .................. 2
  tokenizer_model_type ......... None
  tokenizer_path ............... tokenizer.model
  tokenizer_type ............... ChineseSPTokenizer
  fix_command_token ............ True
  no_pre_tokenize .............. False
  cache_dir .................... None
  use_tfrecords ................ False
  seq_length ................... 512
  mem_length ................... 0
  max_preds_per_seq ............ None
  non_sentence_start ........... 0.0
  sample_one_document .......... False
  load_splits .................. None
  save_splits .................. None
  save_test_data ............... None
  multi_task_data .............. None
  multi_task_ratio ............. 0.0
  multi_seq_length ............. None
  multi_batch_size ............. None
  task ......................... None
  load_pretrained .............. None
  pool_token ................... cls
  cloze_eval ................... False
  multi_token .................. False
  segment_length ............... 0
  loss_func .................... cross_entropy
  block_lm_ratio ............... 0.0
  adapet ....................... False
  pattern_id ................... 0
  fast_decode .................. False
  few_superglue ................ False
  eval_valid ................... False
  validation_metric ............ None
  unidirectional ............... False
  src_seq_length ............... None
  tgt_seq_length ............... None
  adam_beta1 ................... 0.9
  adam_beta2 ................... 0.999
  adam_eps ..................... 1e-08
  optimizer .................... adam
  wsc_negative ................. False
  overwrite .................... False
  no_validation ................ False
  continuous_prompt ............ False
  num_prompt_tokens ............ 0
  prompt_func .................. lstm
  freeze_transformer ........... False
  tune_prefix_layers ........... None
  prefix_prompt ................ 0
  prompt_init .................. False
  deepspeed .................... True
  deepspeed_config ............. ./config/config_block_large_chinese.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  cuda ......................... True
  rank ......................... 0
  world_size ................... 3
  dynamic_loss_scale ........... True
  master_ip .................... 172.31.32.40
  master_port .................. 50521
  eod_token .................... 50000
  persist_state ................ 0
  lazy ......................... False
  transpose .................... False
  data_set_type ................ Block
  samples_per_shard ............ 100
  do_train ..................... 1
  do_valid ..................... 1
  do_test ...................... 1
  iteration .................... 0
  log_dir ...................... ../logs/runs/checkpoints
Resume dataloader
[2022-01-12 08:57:49,502] [INFO] [checkpointing.py:547:forward] Activation Checkpointing Information
[2022-01-12 08:57:49,502] [INFO] [checkpointing.py:548:forward] ----Partition Activations False, CPU CHECKPOINTING False
[2022-01-12 08:57:49,503] [INFO] [checkpointing.py:551:forward] ----contiguous Memory Checkpointing False with 24 total layers
[2022-01-12 08:57:49,503] [INFO] [checkpointing.py:554:forward] ----Synchronization False
[2022-01-12 08:57:49,503] [INFO] [checkpointing.py:555:forward] ----Profiling time in checkpointing False
[2022-01-12 08:57:54,681] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 0
[2022-01-12 08:57:54,681] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 4294967296 to 2147483648.0
[2022-01-12 08:57:54,682] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 0
[2022-01-12 08:57:54,682] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 4294967296 to 2147483648.0
[2022-01-12 08:57:54,682] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 0
[2022-01-12 08:57:54,682] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 4294967296 to 2147483648.0
[2022-01-12 08:57:54,683] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648.0
[2022-01-12 08:57:58,102] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 1
[2022-01-12 08:57:58,102] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 2147483648.0 to 1073741824.0
[2022-01-12 08:57:58,102] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 1
[2022-01-12 08:57:58,103] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 2147483648.0 to 1073741824.0
[2022-01-12 08:57:58,104] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 1
[2022-01-12 08:57:58,104] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 2147483648.0 to 1073741824.0
[2022-01-12 08:57:58,104] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 2147483648.0, reducing to 1073741824.0
[2022-01-12 08:58:00,912] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 2
[2022-01-12 08:58:00,913] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 1073741824.0 to 536870912.0
[2022-01-12 08:58:00,913] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 2
[2022-01-12 08:58:00,913] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 1073741824.0 to 536870912.0
[2022-01-12 08:58:00,914] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 2
[2022-01-12 08:58:00,914] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 1073741824.0 to 536870912.0
[2022-01-12 08:58:00,914] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 1073741824.0, reducing to 536870912.0
[2022-01-12 08:58:02,772] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 3
[2022-01-12 08:58:02,772] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 536870912.0 to 268435456.0
[2022-01-12 08:58:02,773] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 3
[2022-01-12 08:58:02,773] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 536870912.0 to 268435456.0
[2022-01-12 08:58:02,773] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 3
[2022-01-12 08:58:02,773] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 536870912.0 to 268435456.0
[2022-01-12 08:58:02,773] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 536870912.0, reducing to 268435456.0
[2022-01-12 08:58:04,790] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 4
[2022-01-12 08:58:04,790] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 268435456.0 to 134217728.0
[2022-01-12 08:58:04,790] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 4
[2022-01-12 08:58:04,790] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 268435456.0 to 134217728.0
[2022-01-12 08:58:04,791] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 4
[2022-01-12 08:58:04,791] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 268435456.0 to 134217728.0
[2022-01-12 08:58:04,791] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 268435456.0, reducing to 134217728.0
[2022-01-12 08:58:06,815] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 5
[2022-01-12 08:58:06,815] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 5
[2022-01-12 08:58:06,815] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 134217728.0 to 67108864.0
[2022-01-12 08:58:06,815] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 134217728.0 to 67108864.0
[2022-01-12 08:58:06,818] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 5
[2022-01-12 08:58:06,818] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 134217728.0 to 67108864.0
[2022-01-12 08:58:06,818] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 134217728.0, reducing to 67108864.0
[2022-01-12 08:58:08,469] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 6
[2022-01-12 08:58:08,469] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 67108864.0 to 33554432.0
[2022-01-12 08:58:08,469] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 6
[2022-01-12 08:58:08,469] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 67108864.0 to 33554432.0
[2022-01-12 08:58:08,470] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 6
[2022-01-12 08:58:08,470] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 67108864.0 to 33554432.0
[2022-01-12 08:58:08,470] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 67108864.0, reducing to 33554432.0
[2022-01-12 08:58:10,311] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 7
[2022-01-12 08:58:10,311] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 33554432.0 to 16777216.0
[2022-01-12 08:58:10,311] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 7
[2022-01-12 08:58:10,311] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 33554432.0 to 16777216.0
[2022-01-12 08:58:10,311] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 7
[2022-01-12 08:58:10,311] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 33554432.0 to 16777216.0
[2022-01-12 08:58:10,312] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 33554432.0, reducing to 16777216.0
[2022-01-12 08:58:12,331] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 8
[2022-01-12 08:58:12,331] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 16777216.0 to 8388608.0
[2022-01-12 08:58:12,332] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 8
[2022-01-12 08:58:12,332] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 16777216.0 to 8388608.0
[2022-01-12 08:58:12,334] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 8
[2022-01-12 08:58:12,334] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 16777216.0 to 8388608.0
[2022-01-12 08:58:12,334] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16777216.0, reducing to 8388608.0
[2022-01-12 08:58:14,160] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 9
[2022-01-12 08:58:14,160] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 8388608.0 to 4194304.0
[2022-01-12 08:58:14,160] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 9
[2022-01-12 08:58:14,160] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 8388608.0 to 4194304.0
[2022-01-12 08:58:14,161] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 9
[2022-01-12 08:58:14,161] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 8388608.0 to 4194304.0
[2022-01-12 08:58:14,161] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8388608.0, reducing to 4194304.0
[2022-01-12 08:58:16,350] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 10
[2022-01-12 08:58:16,350] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 10
[2022-01-12 08:58:16,350] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 4194304.0 to 2097152.0
[2022-01-12 08:58:16,350] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 4194304.0 to 2097152.0
[2022-01-12 08:58:16,351] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 10
[2022-01-12 08:58:16,352] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 4194304.0 to 2097152.0
[2022-01-12 08:58:16,352] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 4194304.0, reducing to 2097152.0
[2022-01-12 08:58:18,156] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 11
[2022-01-12 08:58:18,156] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 2097152.0 to 1048576.0
[2022-01-12 08:58:18,156] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 11
[2022-01-12 08:58:18,157] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 2097152.0 to 1048576.0
[2022-01-12 08:58:18,158] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 11
[2022-01-12 08:58:18,158] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 2097152.0 to 1048576.0
[2022-01-12 08:58:18,158] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 2097152.0, reducing to 1048576.0
[2022-01-12 08:58:19,969] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 12
[2022-01-12 08:58:19,969] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 1048576.0 to 524288.0
[2022-01-12 08:58:19,970] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 12
[2022-01-12 08:58:19,970] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 1048576.0 to 524288.0
[2022-01-12 08:58:19,972] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 12
[2022-01-12 08:58:19,973] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 1048576.0 to 524288.0
[2022-01-12 08:58:19,973] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 1048576.0, reducing to 524288.0
[2022-01-12 08:58:21,701] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 13
[2022-01-12 08:58:21,701] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 524288.0 to 262144.0
[2022-01-12 08:58:21,702] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 13
[2022-01-12 08:58:21,702] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 524288.0 to 262144.0
[2022-01-12 08:58:21,704] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 13
[2022-01-12 08:58:21,705] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 524288.0 to 262144.0
[2022-01-12 08:58:21,705] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0
[2022-01-12 08:58:24,500] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 14
[2022-01-12 08:58:24,500] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 262144.0 to 131072.0
[2022-01-12 08:58:24,500] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 14
[2022-01-12 08:58:24,500] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 262144.0 to 131072.0
[2022-01-12 08:58:24,502] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 14
[2022-01-12 08:58:24,502] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 262144.0 to 131072.0
[2022-01-12 08:58:24,502] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0
[2022-01-12 08:58:26,510] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 15
[2022-01-12 08:58:26,510] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 15
[2022-01-12 08:58:26,510] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 131072.0 to 65536.0
[2022-01-12 08:58:26,510] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 131072.0 to 65536.0
[2022-01-12 08:58:26,510] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 15
[2022-01-12 08:58:26,511] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 131072.0 to 65536.0
[2022-01-12 08:58:26,511] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 131072.0, reducing to 65536.0
[2022-01-12 08:58:43,717] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 23
[2022-01-12 08:58:43,718] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0
[2022-01-12 08:58:43,718] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 23
[2022-01-12 08:58:43,718] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0
[2022-01-12 08:58:43,719] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 23
[2022-01-12 08:58:43,719] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0
[2022-01-12 08:58:43,719] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0
[2022-01-12 08:58:47,662] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 25
[2022-01-12 08:58:47,662] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
[2022-01-12 08:58:47,663] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 25
[2022-01-12 08:58:47,663] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
[2022-01-12 08:58:47,665] [INFO] [fused_optimizer.py:339:_update_scale] 
Grad overflow on iteration 25
[2022-01-12 08:58:47,665] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
[2022-01-12 08:58:47,665] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0
