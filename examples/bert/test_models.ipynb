{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665d5a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89f719c2",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd06729-5d95-485d-a8f9-46c4fc09be65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载config/settings.py里的超参数(如果使用预加载的模型参数，此文件里相关参数会被覆盖)\n",
      "无可用的GPU, 已自动转成CPU模式\n",
      "当前模型从./config/tiny_config.json里加载模型参数\n",
      "当前模型处于测试模式，会自动加载../data/train_data/test.json作为输入数据\n",
      "构建数据集\n",
      "8\n",
      "avaiable training files:1\n",
      "建立模型的结构\n",
      "模型总参数量: \n",
      "5,926,154 total parameters.\n",
      "5,926,154 training parameters.\n",
      "训练...\n",
      "Worker is training ...\n",
      "1\n",
      "|        5/1000000000 steps|  6319.93 tokens/s| loss   10.67| loss_mlm: 9.982| loss_sp: 0.691| acc_mlm: 0.000| acc_sp: 0.534\n",
      "输入的处理后文本：\n",
      "[CLS]，补足制度短板；注重\u001b[4;31m[MASK]\u001b[0m足企业实际，充分吸\u001b[4;31m[MASK]\u001b[0m企业好的做法和管理\u001b[4;31m[MASK]\u001b[0m验，提炼为\u001b[4;31m[MASK]\u001b[0m度规定\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m求指\u001b[4;31m[MASK]\u001b[0m性、可操作性强。3。问：《通知\u001b[4;31m[MASK]\u001b[0m主要在哪些方\u001b[4;31m[MASK]\u001b[0m进\u001b[4;31m[MASK]\u001b[0m了修订？[SEP]答：《通知\u001b[4;31m[MASK]\u001b[0m包括六个部分内容，覆盖事前、事中\u001b[4;31m  和  \u001b[0m事后的关键\u001b[4;31m[MASK]\u001b[0m节。较原有制度的\u001b[4;31m[MASK]\u001b[0m化主\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m现在\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m ##郡 \u001b[0m几个\u001b[4;31m ##隍 \u001b[0m面。[SEP]\n",
      "\n",
      "填入预测词后的文本：\n",
      "[CLS]，补足制度短板；注重\u001b[4;32m ##侶 \u001b[0m足企业实际，充分吸\u001b[4;32m 105 \u001b[0m企业好的做法和管理\u001b[4;32m ##佶 \u001b[0m验，提炼为\u001b[4;32m ##辉 \u001b[0m度规定\u001b[4;32m ##牦 \u001b[0m\u001b[4;32m  喟  \u001b[0m求指\u001b[4;32m  遒  \u001b[0m性、可操作性强。3。问：《通知\u001b[4;32m ##簧 \u001b[0m主要在哪些方\u001b[4;32m いします\u001b[0m进\u001b[4;32m  懦  \u001b[0m了修订？[SEP]答：《通知\u001b[4;32m ##呗 \u001b[0m包括六个部分内容，覆盖事前、事中\u001b[4;32m  濯  \u001b[0m事后的关键\u001b[4;32m##580\u001b[0m节。较原有制度的\u001b[4;32m  劏  \u001b[0m化主\u001b[4;32m##key\u001b[0m\u001b[4;32m ##] \u001b[0m现在\u001b[4;32m  结  \u001b[0m\u001b[4;32msimon\u001b[0m几个\u001b[4;32m ##鹰 \u001b[0m面。[SEP]\n",
      "\n",
      "原始文本(目标文本)\n",
      "[CLS]，补足制度短板；注重\u001b[4;34m  立  \u001b[0m足企业实际，充分吸\u001b[4;34m  收  \u001b[0m企业好的做法和管理\u001b[4;34m  经  \u001b[0m验，提炼为\u001b[4;34m  制  \u001b[0m度规定\u001b[4;34m  ，  \u001b[0m\u001b[4;34m  力  \u001b[0m求指\u001b[4;34m  导  \u001b[0m性、可操作性强。3。问：《通知\u001b[4;34m  》  \u001b[0m主要在哪些方\u001b[4;34m  面  \u001b[0m进\u001b[4;34m  行  \u001b[0m了修订？[SEP]答：《通知\u001b[4;34m  》  \u001b[0m包括六个部分内容，覆盖事前、事中\u001b[4;34m  和  \u001b[0m事后的关键\u001b[4;34m  环  \u001b[0m节。较原有制度的\u001b[4;34m  变  \u001b[0m化主\u001b[4;34m  要  \u001b[0m\u001b[4;34m  体  \u001b[0m现在\u001b[4;34m  以  \u001b[0m\u001b[4;34m  下  \u001b[0m几个\u001b[4;34m  方  \u001b[0m面。[SEP]\n",
      "\n",
      "\n",
      "|       10/1000000000 steps| 38799.78 tokens/s| loss   10.66| loss_mlm: 9.980| loss_sp: 0.679| acc_mlm: 0.000| acc_sp: 0.800\n",
      "输入的处理后文本：\n",
      "[CLS]投\u001b[4;31m[MASK]\u001b[0m10亿美元在印\u001b[4;31m[MASK]\u001b[0m帮助小企业开展在线业务。印度贸易部长皮\u001b[4;31m[MASK]\u001b[0m什·戈\u001b[4;31m[MASK]\u001b[0m尔(pi##yu##sh##go##ya##l)\u001b[4;31m[MASK]\u001b[0m新\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m的一次安全会\u001b[4;31m[MASK]\u001b[0m上表示：\u001b[4;31m[MASK]\u001b[0m他们可\u001b[4;31m[MASK]\u001b[0m已经投\u001b[4;31m 6991\u001b[0m了10亿美元\u001b[4;31m[unused59]\u001b[0m但\u001b[4;31m[MASK]\u001b[0m果他们每年造成10亿\u001b[4;31m[MASK]\u001b[0m元的损失，\u001b[4;31m[MASK]\u001b[0m他们就必须\u001b[4;31m[MASK]\u001b[0m供10亿美元\u001b[4;31m[MASK]\u001b[0m资金。[SEP]亚马逊将在2014年承诺\u001b[4;31m[MASK]\u001b[0m55亿\u001b[4;31m[MASK]\u001b[0m元投资基础上，[SEP]\n",
      "\n",
      "填入预测词后的文本：\n",
      "[CLS]投\u001b[4;32m ##ᅭ \u001b[0m10亿美元在印\u001b[4;32m ##勢 \u001b[0m帮助小企业开展在线业务。印度贸易部长皮\u001b[4;32m  桓  \u001b[0m什·戈\u001b[4;32m  峡  \u001b[0m尔(pi##yu##sh##go##ya##l)\u001b[4;32m  遒  \u001b[0m新\u001b[4;32m ##俟 \u001b[0m\u001b[4;32m  垣  \u001b[0m的一次安全会\u001b[4;32m  遒  \u001b[0m上表示：\u001b[4;32m ##喟 \u001b[0m他们可\u001b[4;32m  瀑  \u001b[0m已经投\u001b[4;32m  呦  \u001b[0m了10亿美元\u001b[4;32m 1885\u001b[0m但\u001b[4;32m ##钩 \u001b[0m果他们每年造成10亿\u001b[4;32m  苞  \u001b[0m元的损失，\u001b[4;32mmodel\u001b[0m他们就必须\u001b[4;32m  遒  \u001b[0m供10亿美元\u001b[4;32m ##佶 \u001b[0m资金。[SEP]亚马逊将在2014年承诺\u001b[4;32m##580\u001b[0m55亿\u001b[4;32m  觊  \u001b[0m元投资基础上，[SEP]\n",
      "\n",
      "原始文本(目标文本)\n",
      "[CLS]投\u001b[4;34m  资  \u001b[0m10亿美元在印\u001b[4;34m  度  \u001b[0m帮助小企业开展在线业务。印度贸易部长皮\u001b[4;34m  尤  \u001b[0m什·戈\u001b[4;34m  亚  \u001b[0m尔(pi##yu##sh##go##ya##l)\u001b[4;34m  在  \u001b[0m新\u001b[4;34m  德  \u001b[0m\u001b[4;34m  里  \u001b[0m的一次安全会\u001b[4;34m  议  \u001b[0m上表示：\u001b[4;34m[UNK]\u001b[0m他们可\u001b[4;34m  能  \u001b[0m已经投\u001b[4;34m  入  \u001b[0m了10亿美元\u001b[4;34m  。  \u001b[0m但\u001b[4;34m  如  \u001b[0m果他们每年造成10亿\u001b[4;34m  美  \u001b[0m元的损失，\u001b[4;34m  那  \u001b[0m他们就必须\u001b[4;34m  提  \u001b[0m供10亿美元\u001b[4;34m  的  \u001b[0m资金。[SEP]亚马逊将在2014年承诺\u001b[4;34m  的  \u001b[0m55亿\u001b[4;34m  美  \u001b[0m元投资基础上，[SEP]\n",
      "\n",
      "\n",
      "|       15/1000000000 steps| 150196.00 tokens/s| loss   10.66| loss_mlm: 9.976| loss_sp: 0.686| acc_mlm: 0.000| acc_sp: 0.600\n",
      "输入的处理后文本：\n",
      "[CLS]\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m子有着不同的场\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m在星巴克的各大门店都有贩售\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m  ！  \u001b[0m\u001b[4;31m[MASK]\u001b[0m幸\u001b[4;31m[MASK]\u001b[0m酪杯不只是\u001b[4;31m  星  \u001b[0m巴克，瑞幸今年也推出了\u001b[4;31m[MASK]\u001b[0m年马\u001b[4;31m[MASK]\u001b[0m杯。小时候看\u001b[4;31m[MASK]\u001b[0m猫和老鼠》，[SEP]\u001b[4;31m[MASK]\u001b[0m瑞最喜欢的就是奶酪，恨不得住\u001b[4;31m[MASK]\u001b[0m奶\u001b[4;31m[MASK]\u001b[0m做的房子里。\u001b[4;31m[MASK]\u001b[0m想到\u001b[4;31m ##蔷 \u001b[0m个新年，瑞幸\u001b[4;31m[MASK]\u001b[0m它实现了这个愿望，三角形的奶酪杯里面还藏着一\u001b[4;31m[MASK]\u001b[0m小老鼠，[SEP]\n",
      "\n",
      "填入预测词后的文本：\n",
      "[CLS]\u001b[4;32m ##佶 \u001b[0m\u001b[4;32m ##低 \u001b[0m子有着不同的场\u001b[4;32m  遒  \u001b[0m\u001b[4;32m ##侶 \u001b[0m在星巴克的各大门店都有贩售\u001b[4;32m ##˚ \u001b[0m\u001b[4;32m ##瘍 \u001b[0m\u001b[4;32m  人  \u001b[0m幸\u001b[4;32m  旖  \u001b[0m酪杯不只是\u001b[4;32m ##喺 \u001b[0m巴克，瑞幸今年也推出了\u001b[4;32m ##黯 \u001b[0m年马\u001b[4;32m  遒  \u001b[0m杯。小时候看\u001b[4;32m ##侶 \u001b[0m猫和老鼠》，[SEP]\u001b[4;32m  劏  \u001b[0m瑞最喜欢的就是奶酪，恨不得住\u001b[4;32m  侃  \u001b[0m奶\u001b[4;32m  掲  \u001b[0m做的房子里。\u001b[4;32m  檻  \u001b[0m想到\u001b[4;32m ##拱 \u001b[0m个新年，瑞幸\u001b[4;32m  厌  \u001b[0m它实现了这个愿望，三角形的奶酪杯里面还藏着一\u001b[4;32m##cept\u001b[0m小老鼠，[SEP]\n",
      "\n",
      "原始文本(目标文本)\n",
      "[CLS]\u001b[4;34m  的  \u001b[0m\u001b[4;34m  杯  \u001b[0m子有着不同的场\u001b[4;34m  景  \u001b[0m\u001b[4;34m  ，  \u001b[0m在星巴克的各大门店都有贩售\u001b[4;34m  哦  \u001b[0m\u001b[4;34m  ！  \u001b[0m\u001b[4;34m  瑞  \u001b[0m幸\u001b[4;34m  奶  \u001b[0m酪杯不只是\u001b[4;34m  星  \u001b[0m巴克，瑞幸今年也推出了\u001b[4;34m  鼠  \u001b[0m年马\u001b[4;34m  克  \u001b[0m杯。小时候看\u001b[4;34m  《  \u001b[0m猫和老鼠》，[SEP]\u001b[4;34m  杰  \u001b[0m瑞最喜欢的就是奶酪，恨不得住\u001b[4;34m  进  \u001b[0m奶\u001b[4;34m  酪  \u001b[0m做的房子里。\u001b[4;34m  没  \u001b[0m想到\u001b[4;34m  这  \u001b[0m个新年，瑞幸\u001b[4;34m  帮  \u001b[0m它实现了这个愿望，三角形的奶酪杯里面还藏着一\u001b[4;34m  只  \u001b[0m小老鼠，[SEP]\n",
      "\n",
      "\n",
      "|       20/1000000000 steps| 146375.47 tokens/s| loss   10.68| loss_mlm: 9.989| loss_sp: 0.691| acc_mlm: 0.000| acc_sp: 0.600\n",
      "输入的处理后文本：\n",
      "[CLS]是\u001b[4;31m[MASK]\u001b[0m重的。文化传播是需要无数人努力的一件大事\u001b[4;31m[MASK]\u001b[0m而我只是\u001b[4;31m[MASK]\u001b[0m了我热爱的一\u001b[4;31m[MASK]\u001b[0m小\u001b[4;31m[MASK]\u001b[0m。当我知道有这么多外国朋友看到我的视频\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m欢我的视频，能更加\u001b[4;31m[MASK]\u001b[0m解中国，[SEP]我觉得很\u001b[4;31m[MASK]\u001b[0m豪\u001b[4;31m  鶴  \u001b[0m[UNK]拍\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m频是我热爱的事情\u001b[4;31m[MASK]\u001b[0m每\u001b[4;31m[MASK]\u001b[0m好一个视频都\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m  有  \u001b[0m一种满足感[UNK]问当\u001b[4;31m[MASK]\u001b[0m开始\u001b[4;31m[MASK]\u001b[0m摄视频的初衷是怎样的\u001b[4;31m[MASK]\u001b[0m[SEP]\n",
      "\n",
      "填入预测词后的文本：\n",
      "[CLS]是\u001b[4;32m ##ᅭ \u001b[0m重的。文化传播是需要无数人努力的一件大事\u001b[4;32m ##佶 \u001b[0m而我只是\u001b[4;32m ##这 \u001b[0m了我热爱的一\u001b[4;32m ##臺 \u001b[0m小\u001b[4;32m ##勢 \u001b[0m。当我知道有这么多外国朋友看到我的视频\u001b[4;32m  嘭  \u001b[0m\u001b[4;32m  雀  \u001b[0m欢我的视频，能更加\u001b[4;32m ##牦 \u001b[0m解中国，[SEP]我觉得很\u001b[4;32m##ject\u001b[0m豪\u001b[4;32m[unused85]\u001b[0m[UNK]拍\u001b[4;32m##don\u001b[0m\u001b[4;32m  檻  \u001b[0m频是我热爱的事情\u001b[4;32m ##呗 \u001b[0m每\u001b[4;32m ##霆 \u001b[0m好一个视频都\u001b[4;32m  頑  \u001b[0m\u001b[4;32m ##傍 \u001b[0m一种满足感[UNK]问当\u001b[4;32m ##呗 \u001b[0m开始\u001b[4;32m 2016\u001b[0m摄视频的初衷是怎样的\u001b[4;32m  淒  \u001b[0m[SEP]\n",
      "\n",
      "原始文本(目标文本)\n",
      "[CLS]是\u001b[4;34m  沉  \u001b[0m重的。文化传播是需要无数人努力的一件大事\u001b[4;34m  ，  \u001b[0m而我只是\u001b[4;34m  做  \u001b[0m了我热爱的一\u001b[4;34m  件  \u001b[0m小\u001b[4;34m  事  \u001b[0m。当我知道有这么多外国朋友看到我的视频\u001b[4;34m  、  \u001b[0m\u001b[4;34m  喜  \u001b[0m欢我的视频，能更加\u001b[4;34m  了  \u001b[0m解中国，[SEP]我觉得很\u001b[4;34m  自  \u001b[0m豪\u001b[4;34m  。  \u001b[0m[UNK]拍\u001b[4;34m  摄  \u001b[0m\u001b[4;34m  视  \u001b[0m频是我热爱的事情\u001b[4;34m  ，  \u001b[0m每\u001b[4;34m  拍  \u001b[0m好一个视频都\u001b[4;34m  会  \u001b[0m\u001b[4;34m  有  \u001b[0m一种满足感[UNK]问当\u001b[4;34m  初  \u001b[0m开始\u001b[4;34m  拍  \u001b[0m摄视频的初衷是怎样的\u001b[4;34m  ？  \u001b[0m[SEP]\n",
      "\n",
      "\n",
      "|       25/1000000000 steps| 136970.62 tokens/s| loss   10.62| loss_mlm: 9.940| loss_sp: 0.677| acc_mlm: 0.000| acc_sp: 0.800\n",
      "输入的处理后文本：\n",
      "[CLS]\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m  士  \u001b[0m康是苹果公司iphone的\u001b[4;31m ##∶ \u001b[0m要组装商。[SEP]随着\u001b[4;31m  消  \u001b[0m费\u001b[4;31m[MASK]\u001b[0m使用\u001b[4;31m[MASK]\u001b[0m能手机的时间延长\u001b[4;31m[MASK]\u001b[0m以及来自提供低价\u001b[4;31m[MASK]\u001b[0m机的中国制造商的竞争加剧，iphone\u001b[4;31m[MASK]\u001b[0m销售一直在放缓。富士康\u001b[4;31m[MASK]\u001b[0m事\u001b[4;31m[MASK]\u001b[0m刘扬伟去\u001b[4;31m[MASK]\u001b[0m曾表示，[SEP]\n",
      "\n",
      "填入预测词后的文本：\n",
      "[CLS]\u001b[4;32m ##佶 \u001b[0m\u001b[4;32m ##构 \u001b[0m康是苹果公司iphone的\u001b[4;32m ##叨 \u001b[0m要组装商。[SEP]随着\u001b[4;32m ##虫 \u001b[0m费\u001b[4;32m ##晰 \u001b[0m使用\u001b[4;32m##580\u001b[0m能手机的时间延长\u001b[4;32m ##ｂ \u001b[0m以及来自提供低价\u001b[4;32m  遒  \u001b[0m机的中国制造商的竞争加剧，iphone\u001b[4;32m ##硒 \u001b[0m销售一直在放缓。富士康\u001b[4;32m  檻  \u001b[0m事\u001b[4;32m  慮  \u001b[0m刘扬伟去\u001b[4;32m  濯  \u001b[0m曾表示，[SEP]\n",
      "\n",
      "原始文本(目标文本)\n",
      "[CLS]\u001b[4;34m  富  \u001b[0m\u001b[4;34m  士  \u001b[0m康是苹果公司iphone的\u001b[4;34m  主  \u001b[0m要组装商。[SEP]随着\u001b[4;34m  消  \u001b[0m费\u001b[4;34m  者  \u001b[0m使用\u001b[4;34m  智  \u001b[0m能手机的时间延长\u001b[4;34m  ，  \u001b[0m以及来自提供低价\u001b[4;34m  手  \u001b[0m机的中国制造商的竞争加剧，iphone\u001b[4;34m  的  \u001b[0m销售一直在放缓。富士康\u001b[4;34m  董  \u001b[0m事\u001b[4;34m  长  \u001b[0m刘扬伟去\u001b[4;34m  年  \u001b[0m曾表示，[SEP]\n",
      "\n",
      "\n",
      "|       30/1000000000 steps| 136605.22 tokens/s| loss   10.65| loss_mlm: 9.977| loss_sp: 0.674| acc_mlm: 0.000| acc_sp: 0.800\n",
      "输入的处理后文本：\n",
      "[CLS]给好友浇水得福卡第2\u001b[4;31m ##紮 \u001b[0m集福卡途径，是在蚂蚁森林[UNK]给\u001b[4;31m[MASK]\u001b[0m友浇\u001b[4;31m[MASK]\u001b[0m得福卡[UNK]。用户可\u001b[4;31m[MASK]\u001b[0m自\u001b[4;31m[MASK]\u001b[0m选择浇水\u001b[4;31m  克  \u001b[0m数，并\u001b[4;31m[MASK]\u001b[0m醒对方来，7天不收还能退回。[SEP]3运动集福卡第3个\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m  卡  \u001b[0m途径是运动集福，\u001b[4;31m[MASK]\u001b[0m过这个功能要到1\u001b[4;31m[MASK]\u001b[0m17日才上\u001b[4;31m[MASK]\u001b[0m。我\u001b[4;31m[MASK]\u001b[0m可\u001b[4;31m[MASK]\u001b[0m在「\u001b[4;31m[MASK]\u001b[0m付宝运动」中走\u001b[4;31m[MASK]\u001b[0m线\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m满100步即领福卡。[SEP]\n",
      "\n",
      "填入预测词后的文本：\n",
      "[CLS]给好友浇水得福卡第2\u001b[4;32m ##侶 \u001b[0m集福卡途径，是在蚂蚁森林[UNK]给\u001b[4;32m ##瘍 \u001b[0m友浇\u001b[4;32m  桓  \u001b[0m得福卡[UNK]。用户可\u001b[4;32m mod \u001b[0m自\u001b[4;32m ##佶 \u001b[0m选择浇水\u001b[4;32m  键  \u001b[0m数，并\u001b[4;32m ##イト\u001b[0m醒对方来，7天不收还能退回。[SEP]3运动集福卡第3个\u001b[4;32m  觊  \u001b[0m\u001b[4;32m  票  \u001b[0m\u001b[4;32m  舟  \u001b[0m途径是运动集福，\u001b[4;32m ##腺 \u001b[0m过这个功能要到1\u001b[4;32m  喟  \u001b[0m17日才上\u001b[4;32m  圜  \u001b[0m。我\u001b[4;32m ##峒 \u001b[0m可\u001b[4;32m ##呗 \u001b[0m在「\u001b[4;32m ##cn\u001b[0m付宝运动」中走\u001b[4;32m 2016\u001b[0m线\u001b[4;32m ##弧 \u001b[0m\u001b[4;32m  撥  \u001b[0m满100步即领福卡。[SEP]\n",
      "\n",
      "原始文本(目标文本)\n",
      "[CLS]给好友浇水得福卡第2\u001b[4;34m  个  \u001b[0m集福卡途径，是在蚂蚁森林[UNK]给\u001b[4;34m  好  \u001b[0m友浇\u001b[4;34m  水  \u001b[0m得福卡[UNK]。用户可\u001b[4;34m  以  \u001b[0m自\u001b[4;34m  己  \u001b[0m选择浇水\u001b[4;34m  克  \u001b[0m数，并\u001b[4;34m  提  \u001b[0m醒对方来，7天不收还能退回。[SEP]3运动集福卡第3个\u001b[4;34m  集  \u001b[0m\u001b[4;34m  福  \u001b[0m\u001b[4;34m  卡  \u001b[0m途径是运动集福，\u001b[4;34m  不  \u001b[0m过这个功能要到1\u001b[4;34m  月  \u001b[0m17日才上\u001b[4;34m  线  \u001b[0m。我\u001b[4;34m  们  \u001b[0m可\u001b[4;34m  以  \u001b[0m在「\u001b[4;34m  支  \u001b[0m付宝运动」中走\u001b[4;34m  路  \u001b[0m线\u001b[4;34m  ，  \u001b[0m\u001b[4;34m  走  \u001b[0m满100步即领福卡。[SEP]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       35/1000000000 steps| 134692.52 tokens/s| loss   10.65| loss_mlm: 9.974| loss_sp: 0.677| acc_mlm: 0.000| acc_sp: 0.800\n",
      "输入的处理后文本：\n",
      "[CLS]现在的比\u001b[4;31m  阈  \u001b[0m特丽斯\u001b[4;31m[MASK]\u001b[0m主（pr##ince##ss##be\u001b[4;31m[MASK]\u001b[0m##ric##e）\u001b[4;31m[MASK]\u001b[0m尤金妮公主（pr##ince##sse##ug##en\u001b[4;31m ##橋 \u001b[0m\u001b[4;31m[MASK]\u001b[0m就不是\u001b[4;31m[MASK]\u001b[0m在职王室成员[UNK]，[SEP]\u001b[4;31m  未  \u001b[0m来哈里一家在加拿大\u001b[4;31m[MASK]\u001b[0m活时\u001b[4;31m[MASK]\u001b[0m安保费用将成为亟待解决\u001b[4;31m[MASK]\u001b[0m问题。或\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m  这  \u001b[0m也就是\u001b[4;31m[MASK]\u001b[0m何加拿大政府\u001b[4;31m[MASK]\u001b[0m员此前也参加\u001b[4;31m[MASK]\u001b[0m1月13日英\u001b[4;31m[MASK]\u001b[0m王室特别会议的原因。\u001b[4;31m[MASK]\u001b[0m开资\u001b[4;31m[MASK]\u001b[0m显示，整个英国王室每[SEP]\n",
      "\n",
      "填入预测词后的文本：\n",
      "[CLS]现在的比\u001b[4;32m  hp \u001b[0m特丽斯\u001b[4;32m ##侶 \u001b[0m主（pr##ince##ss##be\u001b[4;32mcurve\u001b[0m##ric##e）\u001b[4;32m  顫  \u001b[0m尤金妮公主（pr##ince##sse##ug##en\u001b[4;32m  線  \u001b[0m\u001b[4;32m ##⑩ \u001b[0m就不是\u001b[4;32m ##莠 \u001b[0m在职王室成员[UNK]，[SEP]\u001b[4;32m  貨  \u001b[0m来哈里一家在加拿大\u001b[4;32m  檻  \u001b[0m活时\u001b[4;32m  呐  \u001b[0m安保费用将成为亟待解决\u001b[4;32m ##呗 \u001b[0m问题。或\u001b[4;32m ##呗 \u001b[0m\u001b[4;32m  晗  \u001b[0m也就是\u001b[4;32m  掲  \u001b[0m何加拿大政府\u001b[4;32m  檻  \u001b[0m员此前也参加\u001b[4;32m  檻  \u001b[0m1月13日英\u001b[4;32m ##cn\u001b[0m王室特别会议的原因。\u001b[4;32m ##霆 \u001b[0m开资\u001b[4;32m ##羹 \u001b[0m显示，整个英国王室每[SEP]\n",
      "\n",
      "原始文本(目标文本)\n",
      "[CLS]现在的比\u001b[4;34m  阿  \u001b[0m特丽斯\u001b[4;34m  公  \u001b[0m主（pr##ince##ss##be\u001b[4;34m ##at\u001b[0m##ric##e）\u001b[4;34m  和  \u001b[0m尤金妮公主（pr##ince##sse##ug##en\u001b[4;34m ##ie\u001b[0m\u001b[4;34m  ）  \u001b[0m就不是\u001b[4;34m[UNK]\u001b[0m在职王室成员[UNK]，[SEP]\u001b[4;34m  未  \u001b[0m来哈里一家在加拿大\u001b[4;34m  生  \u001b[0m活时\u001b[4;34m  的  \u001b[0m安保费用将成为亟待解决\u001b[4;34m  的  \u001b[0m问题。或\u001b[4;34m  许  \u001b[0m\u001b[4;34m  这  \u001b[0m也就是\u001b[4;34m  为  \u001b[0m何加拿大政府\u001b[4;34m  官  \u001b[0m员此前也参加\u001b[4;34m  了  \u001b[0m1月13日英\u001b[4;34m  国  \u001b[0m王室特别会议的原因。\u001b[4;34m  公  \u001b[0m开资\u001b[4;34m  料  \u001b[0m显示，整个英国王室每[SEP]\n",
      "\n",
      "\n",
      "|       40/1000000000 steps| 132544.15 tokens/s| loss   10.65| loss_mlm: 9.963| loss_sp: 0.689| acc_mlm: 0.000| acc_sp: 0.600\n",
      "输入的处理后文本：\n",
      "[CLS]表现优于行业；近\u001b[4;31m[MASK]\u001b[0m对低\u001b[4;31m[MASK]\u001b[0m白奶加大推广力度，[SEP]\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m  配  \u001b[0m消费需求变化趋\u001b[4;31m[MASK]\u001b[0m，看好公司\u001b[4;31m##cal\u001b[0m远\u001b[4;31m[MASK]\u001b[0m略布局。冷饮\u001b[4;31m[MASK]\u001b[0m续较\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m争力，高端新品升级\u001b[4;31m[MASK]\u001b[0m\u001b[4;31m[MASK]\u001b[0m的明显结构性价格\u001b[4;31m  增  \u001b[0m量。奶粉渐平\u001b[4;31m[MASK]\u001b[0m，跨品类长远可期奶粉业务2019年增速\u001b[4;31m  回  \u001b[0m落，\u001b[4;31m[MASK]\u001b[0m业增长趋\u001b[4;31m[MASK]\u001b[0m稳，但高端升级趋势\u001b[4;31m[MASK]\u001b[0m著、国\u001b[4;31m[MASK]\u001b[0m品牌红利延续，伊利[SEP]\n",
      "\n",
      "填入预测词后的文本：\n",
      "[CLS]表现优于行业；近\u001b[4;32m ##90\u001b[0m对低\u001b[4;32m ##汩 \u001b[0m白奶加大推广力度，[SEP]\u001b[4;32m  咎  \u001b[0m\u001b[4;32m ##× \u001b[0m消费需求变化趋\u001b[4;32m  у  \u001b[0m，看好公司\u001b[4;32m##ude\u001b[0m远\u001b[4;32m  癒  \u001b[0m略布局。冷饮\u001b[4;32m ##惰 \u001b[0m续较\u001b[4;32m ##委 \u001b[0m\u001b[4;32m  觊  \u001b[0m争力，高端新品升级\u001b[4;32m  艹  \u001b[0m\u001b[4;32m  懦  \u001b[0m的明显结构性价格\u001b[4;32m  尉  \u001b[0m量。奶粉渐平\u001b[4;32m ##糯 \u001b[0m，跨品类长远可期奶粉业务2019年增速\u001b[4;32m  変  \u001b[0m落，\u001b[4;32m  檻  \u001b[0m业增长趋\u001b[4;32m  劏  \u001b[0m稳，但高端升级趋势\u001b[4;32m ##▉ \u001b[0m著、国\u001b[4;32m ##涂 \u001b[0m品牌红利延续，伊利[SEP]\n",
      "\n",
      "原始文本(目标文本)\n",
      "[CLS]表现优于行业；近\u001b[4;34m  期  \u001b[0m对低\u001b[4;34m  温  \u001b[0m白奶加大推广力度，[SEP]\u001b[4;34m  匹  \u001b[0m\u001b[4;34m  配  \u001b[0m消费需求变化趋\u001b[4;34m  势  \u001b[0m，看好公司\u001b[4;34m  长  \u001b[0m远\u001b[4;34m  战  \u001b[0m略布局。冷饮\u001b[4;34m  延  \u001b[0m续较\u001b[4;34m  强  \u001b[0m\u001b[4;34m  竞  \u001b[0m争力，高端新品升级\u001b[4;34m  带  \u001b[0m\u001b[4;34m  来  \u001b[0m的明显结构性价格\u001b[4;34m  增  \u001b[0m量。奶粉渐平\u001b[4;34m  稳  \u001b[0m，跨品类长远可期奶粉业务2019年增速\u001b[4;34m  回  \u001b[0m落，\u001b[4;34m  行  \u001b[0m业增长趋\u001b[4;34m  平  \u001b[0m稳，但高端升级趋势\u001b[4;34m  显  \u001b[0m著、国\u001b[4;34m  产  \u001b[0m品牌红利延续，伊利[SEP]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1b23a9a1cbfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"训练...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/wang/research/wudao/train_utils/BertTrainer.py\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(args, model)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# CPU Mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mworker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/wang/research/wudao/train_utils/BertTrainer.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(proc_id, gpu_ranks, args, model)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemo_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/wang/research/wudao/train_utils/BertTrainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, args, gpu_id, rank, loader, demo_loader, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/wang/research/wudao/train_utils/BertTrainer.py\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(self, batch, model)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_sp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mloss_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtgt_mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_sp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0moutput_mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_sp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_sp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_mlm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_sp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/wang/research/wudao/examples/bert/model_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, seg)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mloss_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/wang/research/wudao/nets/encoders.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emb, seg)\u001b[0m\n\u001b[1;32m    105\u001b[0m                                                      prev_attn=prev_attn)\n\u001b[1;32m    106\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 hidden, prev_attn = self.transformer[i](hidden, mask, position_bias=position_bias,\n\u001b[0m\u001b[1;32m    108\u001b[0m                                                         \u001b[0mhas_residual_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_residual_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                                         prev_attn=prev_attn)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/wang/research/wudao/nets/BertTransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden, mask, position_bias, has_residual_attention, prev_attn)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_attn_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 初始化\n",
    "import sys\n",
    "root_dir='/Users/guoqiang/Documents/wang/research/wudao/'\n",
    "\n",
    "sys.path.append(root_dir)\n",
    "from data_utils.BertDataset import BertDataset\n",
    "from nets.BertEmbeddings import WordPosSegEmbedding\n",
    "from nets.encoders import TransformerEncoder\n",
    "from nets.targets import BertTarget\n",
    "from model_bert import Model\n",
    "import glob\n",
    "from utils.struct_nav import str2tokenizer, str2embedding, str2encoder, str2target\n",
    "from arguments import *\n",
    "import train_utils.BertTrainer as trainer\n",
    "\n",
    "isTEST = 1  # 测试模式，模型会读取./data/train_data/test.json作为输入数据\n",
    "model_config_path = \"./config/tiny_config.json\"  # 加载预先调好的模型参数，默认为BERT基础版。如需自行设置参数请将此变量设置为空值\"\"\n",
    "\n",
    "\n",
    "print(\"加载config/settings.py里的超参数(如果使用预加载的模型参数，此文件里相关参数会被覆盖)\")\n",
    "args = build_args(root_dir=root_dir)\n",
    "if model_config_path:\n",
    "    print(\"当前模型从%s里加载模型参数\" % model_config_path)\n",
    "    args = load_hyperparam(args, config_path=model_config_path)\n",
    "if isTEST:\n",
    "    print(\"当前模型处于测试模式，会自动加载../data/train_data/test.json作为输入数据\")\n",
    "    args = load_hyperparam(args, config_path=\"./config/test_config.json\")\n",
    "else:\n",
    "    print(\"当前模型处于正常模式\")\n",
    "    \n",
    "    \n",
    "\n",
    "args.file_types=['json']\n",
    "if __name__=='__main__':\n",
    "    print(\"构建数据集\")\n",
    "    print(args.preprocess_num)\n",
    "    tokenizer = str2tokenizer[args.tokenizer](args)\n",
    "    args.tokenizer = tokenizer\n",
    "    dataset = BertDataset(args, tokenizer.vocab, tokenizer)\n",
    "    \n",
    "    #dataset.build_and_save(1,merge=True,file_preproces_dist=True)\n",
    "    #\n",
    "    print(\"建立模型的结构\")\n",
    "    embedding = str2embedding[args.embedding](args, len(args.tokenizer.vocab))\n",
    "    encoder = str2encoder[args.encoder](args)\n",
    "    target = str2target[args.target](args, len(args.tokenizer.vocab))\n",
    "    model_struct = Model(args, embedding, encoder, target)\n",
    "    # model_struct\n",
    "    print(\"模型总参数量: \")\n",
    "    get_total_params_num_from_model(model_struct)\n",
    "    \n",
    "    print(\"训练...\")\n",
    "    trainer.train_and_validate(args, model_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27554ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91f681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80d1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
